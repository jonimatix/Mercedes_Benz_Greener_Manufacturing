{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt_all_cleaned = pd.read_csv(\"../../data/Mercedes_Benz_Greener_Manufacturing/data/dt_all_transformed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt_train_raw = dt_all_cleaned.loc[dt_all_cleaned[\"IsTrainTest\"] == \"train\"]\n",
    "dt_test_raw = dt_all_cleaned.loc[dt_all_cleaned[\"IsTrainTest\"] == \"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Duplicated cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Drop dup cols in dt_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# duplicated cols in dt_all\n",
    "cols_dup_all_toDrop = dt_all_cleaned.T.duplicated()[dt_all_cleaned.T.duplicated() == True].index.values\n",
    "dt_all_cleaned = dt_all_cleaned.drop(cols_dup_all_toDrop, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8418, 343)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_all_cleaned.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Rename the remaining dup cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# duplicated cols in dt_train\n",
    "cols_dup_train = dt_train_raw.T.duplicated(keep = False)[dt_train_raw.T.duplicated(keep = False) == True].index.values\n",
    "# duplicated cols in dt_test\n",
    "cols_dup_test = dt_test_raw.T.duplicated(keep = False)[dt_test_raw.T.duplicated(keep = False) == True].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change col names for cols_dup_train and cols_dup_test\n",
    "dict_dup_train = {x: \"dup_train_\" + x for x in list(cols_dup_train)}\n",
    "dt_all_cleaned = dt_all_cleaned.rename(columns = dict_dup_train)\n",
    "dict_dup_test = {x: \"dup_test_\" + x for x in list(cols_dup_test[cols_dup_test != \"y\"])}\n",
    "dt_all_cleaned = dt_all_cleaned.rename(columns = dict_dup_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8418, 343)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_all_cleaned.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Duplicated rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Rename them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cols_cat\n",
    "cols_cat = dt_all_cleaned.drop(\"IsTrainTest\", axis = 1).select_dtypes(include = ['object']).columns.values\n",
    "# cols_int\n",
    "cols_int = dt_all_cleaned.drop(\"ID\", axis = 1).select_dtypes(include = ['int64']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt_all_cleaned.loc[:, \"IsDupRow_All\"] = dt_all_cleaned.drop([\"ID\", \"y\"], axis = 1).duplicated(keep = False).astype(\"int64\")\n",
    "dt_all_cleaned.loc[:, \"IsDupRow_Cat\"] = dt_all_cleaned.drop([\"ID\", \"y\"], axis = 1)[cols_cat].duplicated(keep = False).astype(\"int64\")\n",
    "dt_all_cleaned.loc[:, \"IsDupRow_Int\"] = dt_all_cleaned.drop([\"ID\", \"y\"], axis = 1)[cols_int].duplicated(keep = False).astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8418, 346)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_all_cleaned.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Mean y of duplicated row(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Remove single values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# single value cols in dt_train\n",
    "cols_single_train = []\n",
    "for col in dt_all_cleaned.loc[dt_all_cleaned[\"IsTrainTest\"] == \"train\"].drop([\"y\", \"IsTrainTest\"], axis = 1).columns.values:\n",
    "    len_unique = len(np.unique(dt_all_cleaned.loc[dt_all_cleaned[\"IsTrainTest\"] == \"train\"][col].values))\n",
    "    if len_unique == 1:\n",
    "        cols_single_train.append(col)\n",
    "# single value cols in dt_test\n",
    "cols_single_test = []\n",
    "for col in dt_all_cleaned.loc[dt_all_cleaned[\"IsTrainTest\"] == \"test\"].drop([\"y\", \"IsTrainTest\"], axis = 1).columns.values:\n",
    "    len_unique = len(np.unique(dt_all_cleaned.loc[dt_all_cleaned[\"IsTrainTest\"] == \"test\"][col].values))\n",
    "    if len_unique == 1:\n",
    "        cols_single_test.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change col names for cols_single_train and cols_single_test\n",
    "dict_single_train = {x: \"single_train_\" + x for x in cols_single_train}\n",
    "dt_all_cleaned = dt_all_cleaned.rename(columns = dict_single_train)\n",
    "dict_single_test = {x: \"single_test_\" + x for x in cols_single_test}\n",
    "dt_all_cleaned = dt_all_cleaned.rename(columns = dict_single_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_all_cleaned.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Remove complimentary cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols_int = dt_all_cleaned.drop(\"ID\", axis = 1).select_dtypes(include = ['int64']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def removeCompCols(dt, cols):\n",
    "    seen = []\n",
    "    col2s = []\n",
    "    nrow = dt.shape[0]\n",
    "    for col1 in cols_int:\n",
    "        for col2 in cols_int:\n",
    "            compliment = sum(dt[col1].values + dt[col2].values)\n",
    "            same = np.sum(dt[col1] == dt[col2])\n",
    "            if (compliment == nrow) & (same == 0):\n",
    "                seen.append((col1, col2))\n",
    "                if (col2, col1) not in seen:\n",
    "                    col2s.append(col2)\n",
    "                    print(col1, col2)\n",
    "    return col2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_comp = removeCompCols(dt_all_cleaned, cols_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt_all_cleaned = dt_all_cleaned.drop(cols_comp, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_all_cleaned.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Save cols_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cols_raw\n",
    "cols_raw = dt_all_cleaned.drop([\"ID\", \"y\", \"IsTrainTest\", \"IsDupRow_All\", \"IsDupRow_Cat\", \"IsDupRow_Int\"\n",
    "                            , \"X0\", \"X1\", \"X2\", \"X3\", \"X4\", \"X5\", \"X6\", \"X8\"], axis = 1).columns.values\n",
    "pickle.dump(cols_raw, open( \"../../data/Mercedes_Benz_Greener_Manufacturing/data/cols_raw.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dt_all_cleaned\n",
    "dt_all_cleaned.to_csv(\"../../data/Mercedes_Benz_Greener_Manufacturing/data/dt_all_cleaned.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt_all_cleaned.dup"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
