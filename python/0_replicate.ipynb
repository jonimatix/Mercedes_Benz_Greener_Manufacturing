{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../../data/Mercedes_Benz_Greener_Manufacturing/raw/train.csv\")\n",
    "test = pd.read_csv(\"../../data/Mercedes_Benz_Greener_Manufacturing/raw/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_cat = train.select_dtypes(include = ['object']).columns.values\n",
    "cols_cat = cols_cat.tolist()\n",
    "cols_bin = train.select_dtypes(include = ['int64']).columns.values\n",
    "cols_bin = cols_bin[cols_bin != \"ID\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in cols_cat:\n",
    "    x = list(set(list(train[c].values) + list(test[c].values))) \n",
    "    x.sort()\n",
    "    x.sort(key = len)\n",
    "    dt_labelEncode_c = pd.DataFrame({\"Encode_Label_\" + c: [i for i in range(1, (len(x) + 1))]\n",
    "                                     , c: x})\n",
    "\n",
    "    train = pd.merge(train, dt_labelEncode_c, on = c)\n",
    "    test = pd.merge(test, dt_labelEncode_c, on = c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TargetMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTargetMean(dt_train, dt_test, cols, k = 3, random_state = 888):\n",
    "\n",
    "    if k == 1:\n",
    "        train_cp = dt_train.copy()\n",
    "        test_cp = dt_test.copy()\n",
    "        for c in cols:\n",
    "            x = train_cp.groupby([c])[\"y\"].mean()\n",
    "            dt_targetMean_c = pd.DataFrame({c: x.index\n",
    "                                           , \"TargetMean_\" + c: x.values})\n",
    "            train_cp = pd.merge(dt_targetMean_c, train_cp, on = c)\n",
    "\n",
    "            test_cp = pd.merge(dt_targetMean_c, test_cp, on = c, how = \"right\")\n",
    "            test_cp = test_cp.fillna(np.mean(train_cp.y))\n",
    "\n",
    "        return train_cp, test_cp\n",
    "    else:\n",
    "        for col in cols:\n",
    "            X_train_fold = pd.DataFrame()\n",
    "            X_test_fold = pd.DataFrame()\n",
    "\n",
    "            skf = StratifiedKFold(n_splits = k, random_state = random_state)\n",
    "\n",
    "            for i, (ind_in, ind_out) in enumerate(skf.split(dt_train, dt_train[col].values)):\n",
    "                X_in, X_out = dt_train.iloc[ind_in], dt_train.iloc[ind_out]\n",
    "                # targetMean in\n",
    "                dt_targetMean_fold = pd.DataFrame({col: X_in.groupby([col])[\"y\"].mean().index\n",
    "                                                  , \"Encode_TargetMean_\" + col: X_in.groupby([col])[\"y\"].mean()})\n",
    "                # merge targetMean out\n",
    "                X_out_fold = pd.merge(X_out, dt_targetMean_fold, on = col, how = \"left\")\n",
    "                X_out_fold = X_out_fold.fillna(np.mean(X_in.y))\n",
    "\n",
    "                # concat X_out_fold\n",
    "                X_train_fold = pd.concat([X_train_fold, X_out_fold])\n",
    "\n",
    "                # merge with test\n",
    "                dt_targetMean_fold = dt_targetMean_fold.rename(columns = {\"Encode_TargetMean_\" + col: \"Encode_TargetMean_fold_\" + col + \"_\" + str(i)})\n",
    "                if i == 0:\n",
    "                    X_test_fold = pd.merge(dt_test, dt_targetMean_fold, on = col, how = \"left\")\n",
    "                else:\n",
    "                    X_test_fold = pd.merge(X_test_fold, dt_targetMean_fold, on = col, how = \"left\")\n",
    "\n",
    "                # mean for test\n",
    "                cols_encode_fold = X_test_fold.filter(regex = \"Encode_TargetMean_fold_\").columns.values\n",
    "                X_test_fold[\"Encode_TargetMean_\" + col] = X_test_fold[cols_encode_fold].mean(axis = 1)\n",
    "                X_test_fold = X_test_fold.drop(cols_encode_fold, axis = 1)\n",
    "                X_test_fold = X_test_fold.fillna(np.mean(X_in.y))\n",
    "    \n",
    "    return X_train_fold, X_test_fold \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OutlierMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getOutlierMarker(dt_train, dt_test, perc = 100):\n",
    "    \n",
    "    dt_train_cp = dt_train.copy()\n",
    "    dt_test_cp = dt_test.copy()\n",
    "    \n",
    "    # outlier\n",
    "    bin_y = pd.qcut(dt_train_cp.y.values, perc, labels = [i for i in range(1, perc + 1)]).astype(\"int64\")\n",
    "    dt_outliers = dt_train_cp.iloc[bin_y == perc]\n",
    "    \n",
    "    cols_types = [\"Cat\", \"Bin\", \"All\", \"X0\", \"X5\"]\n",
    "    for cols_type in cols_types:\n",
    "        if cols_type == \"Cat\":\n",
    "            cols = cols_cat\n",
    "        elif cols_type == \"Bin\":\n",
    "            cols = cols_bin\n",
    "        elif cols_type == \"All\":\n",
    "            cols = cols_cat + cols_bin\n",
    "        else:\n",
    "            cols = [cols_type]\n",
    "            \n",
    "        # calc int_outlierMarker_train, int_outlierMarker_test\n",
    "        int_outlierMarker_train = np.zeros(dt_train_cp.shape[0])\n",
    "        int_outlierMarker_test = np.zeros(dt_test_cp.shape[0])\n",
    "        for i in range(1, dt_outliers.shape[0] + 1):\n",
    "            dt_outliers_i = dt_outliers.iloc[(i - 1):i, :][cols]\n",
    "\n",
    "            # calc int_outlierMarker_train_i\n",
    "            int_outlierMarker_train_i = np.zeros(dt_train_cp.shape[0])\n",
    "            for col in dt_outliers_i.columns.values:\n",
    "                for val in dt_outliers_i[col].values:\n",
    "                    int_outlierMarker_train_i += (dt_train_cp[col].values == val).astype(\"int64\")\n",
    "            # calc int_outlierMarker_test_i\n",
    "            int_outlierMarker_test_i = np.zeros(dt_test_cp.shape[0])\n",
    "            for col in dt_outliers_i.columns.values:\n",
    "                for val in dt_outliers_i[col].values:\n",
    "                    int_outlierMarker_test_i += (dt_test_cp[col].values == val).astype(\"int64\")\n",
    "\n",
    "            int_outlierMarker_train += int_outlierMarker_train_i\n",
    "            int_outlierMarker_test += int_outlierMarker_test_i\n",
    "    \n",
    "        # add as column\n",
    "        dt_train_cp.loc[:, \"FeatEng_OutlierMaker_\" + cols_type] = int_outlierMarker_train\n",
    "        dt_test_cp.loc[:, \"FeatEng_OutlierMaker_\" + cols_type] = int_outlierMarker_test\n",
    "        \n",
    "    return dt_train_cp, dt_test_cp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension Reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# standardize\n",
    "train_norm = StandardScaler().fit_transform(train.drop([\"y\"] + cols_cat, axis=1))\n",
    "test_norm = StandardScaler().fit_transform(test.drop(cols_cat, axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_comp = 30\n",
    "n_comp_pca = 100\n",
    "\n",
    "# tSVD\n",
    "tsvd = TruncatedSVD(n_components=n_comp, random_state=420)\n",
    "tsvd_results_train = tsvd.fit_transform(train_norm)\n",
    "tsvd_results_test = tsvd.transform(test_norm)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=n_comp_pca, random_state=420)\n",
    "pca2_results_train = pca.fit_transform(train_norm)\n",
    "pca2_results_test = pca.transform(test_norm)\n",
    "\n",
    "# ICA\n",
    "ica = FastICA(n_components=n_comp, random_state=420)\n",
    "ica2_results_train = ica.fit_transform(train_norm)\n",
    "ica2_results_test = ica.transform(test_norm)\n",
    "\n",
    "# GRP\n",
    "grp = GaussianRandomProjection(n_components=n_comp, eps=0.1, random_state=420)\n",
    "grp_results_train = grp.fit_transform(train_norm)\n",
    "grp_results_test = grp.transform(test_norm)\n",
    "\n",
    "# SRP\n",
    "srp = SparseRandomProjection(n_components=n_comp, dense_output=True, random_state=420)\n",
    "srp_results_train = srp.fit_transform(train_norm)\n",
    "srp_results_test = srp.transform(test_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append decomposition components to datasets\n",
    "for i in range(1, n_comp + 1):\n",
    "\n",
    "    train['ICA_' + str(i)] = ica2_results_train[:, i - 1]\n",
    "    test['ICA_' + str(i)] = ica2_results_test[:, i - 1]\n",
    "\n",
    "    train['TSVD_' + str(i)] = tsvd_results_train[:, i - 1]\n",
    "    test['TSVD_' + str(i)] = tsvd_results_test[:, i - 1]\n",
    "\n",
    "    train['GRP_' + str(i)] = grp_results_train[:, i - 1]\n",
    "    test['GRP_' + str(i)] = grp_results_test[:, i - 1]\n",
    "\n",
    "    train['SRP_' + str(i)] = srp_results_train[:, i - 1]\n",
    "    test['SRP_' + str(i)] = srp_results_test[:, i - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, n_comp_pca + 1):\n",
    "    \n",
    "    train['PCA_' + str(i)] = pca2_results_train[:, i - 1]\n",
    "    test['PCA_' + str(i)] = pca2_results_test[:, i - 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# r_2 for xgboost\n",
    "def r_2(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'score', r2_score(labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_all\n",
    "y_train_all = train.y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TargetMean\n",
      "OutlierMaker\n",
      "TargetMean\n",
      "OutlierMaker\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/noahhhhhh/Env/deepNoah/lib/python3.5/site-packages/ipykernel_launcher.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: Score 0.554627\n",
      "TargetMean\n",
      "OutlierMaker\n",
      "TargetMean\n",
      "OutlierMaker\n",
      "Fold 1: Score 0.603572\n",
      "TargetMean\n",
      "OutlierMaker\n",
      "TargetMean\n",
      "OutlierMaker\n",
      "Fold 2: Score 0.598408\n",
      "TargetMean\n",
      "OutlierMaker\n",
      "TargetMean\n",
      "OutlierMaker\n",
      "Fold 3: Score 0.415922\n",
      "TargetMean\n",
      "OutlierMaker\n",
      "TargetMean\n",
      "OutlierMaker\n",
      "Fold 4: Score 0.572514\n",
      "TargetMean\n",
      "OutlierMaker\n",
      "TargetMean\n",
      "OutlierMaker\n",
      "Fold 5: Score 0.594455\n",
      "TargetMean\n",
      "OutlierMaker\n",
      "TargetMean\n",
      "OutlierMaker\n",
      "Fold 6: Score 0.633076\n",
      "TargetMean\n",
      "OutlierMaker\n",
      "TargetMean\n",
      "OutlierMaker\n",
      "Fold 7: Score 0.622258\n",
      "=====================\n",
      "Final Score 0.574354 ; sd 0.064297\n",
      "=====================\n"
     ]
    }
   ],
   "source": [
    "k = 8\n",
    "# bin\n",
    "bin_y = pd.qcut(y_train_all, k, labels = [i for i in range(1, k + 1)]).astype(\"int64\")\n",
    "# stratified kfold\n",
    "skf = StratifiedKFold(n_splits = k, shuffle = True, random_state = 888)\n",
    "\n",
    "score_skf_valid = 0\n",
    "score_skf = []\n",
    "preds_skf_test = []\n",
    "dt_preds_test = []\n",
    "for i, (ind_train, ind_valid) in enumerate(skf.split(train, bin_y)):\n",
    "    # X, y\n",
    "    X_train, X_valid = train.iloc[ind_train], train.iloc[ind_valid]\n",
    "    \n",
    "    # featEng: TargetMean\n",
    "    # train, valid\n",
    "    X_train_transform, X_valid_transform = getTargetMean(X_train, X_valid, cols_cat, 1) # targetMean\n",
    "    X_train_transform, X_valid_transform = getOutlierMarker(X_train_transform, X_valid_transform) # outlierMaker\n",
    "    \n",
    "    y_train_transform, y_valid_transform = X_train_transform.y.values, X_valid_transform.y.values\n",
    "    X_train_transform, X_valid_transform = X_train_transform.drop([\"y\"] + cols_cat, axis = 1), X_valid_transform.drop([\"y\"] + cols_cat, axis = 1)\n",
    "    \n",
    "    # test\n",
    "    _, X_test_transform = getTargetMean(X_train, test, cols_cat, 1) # targetMean\n",
    "    _, X_test_transform = getOutlierMarker(X_train, X_test_transform) # outlierMaker\n",
    "    X_test_transform = X_test_transform.drop(cols_cat, axis = 1)\n",
    "    \n",
    "    # featEng: Outlier\n",
    "    # train, valid\n",
    "    \n",
    "    # xgb.DMatrix\n",
    "    dmx_train = xgb.DMatrix(X_train_transform, label = y_train_transform)\n",
    "    dmx_valid = xgb.DMatrix(X_valid_transform, label = y_valid_transform)\n",
    "    dmx_test = xgb.DMatrix(X_test_transform)\n",
    "    ls_watch =  [(dmx_train, 'train'), (dmx_valid, 'eval')]\n",
    "    \n",
    "    # params\n",
    "    params_xgb = {\n",
    "        \"objective\": \"reg:linear\"\n",
    "        , \"booster\": \"gbtree\"\n",
    "        , \"learning_rate\": 0.005\n",
    "        , \"subsample\": .9\n",
    "        , \"colsample\": .8\n",
    "        , \"max_depth\": 2\n",
    "        , \"alpha\": 1\n",
    "        , \"lambda\": 2\n",
    "        , \"gamma\": 20\n",
    "        , \"base_score\": np.mean(y_train_transform)\n",
    "    }\n",
    "    \n",
    "    # model\n",
    "    model_xgb = xgb.train(params_xgb, dmx_train, evals = ls_watch\n",
    "                          , num_boost_round = 5000\n",
    "                          , feval = r_2, maximize = True, early_stopping_rounds = 50\n",
    "                          , verbose_eval = False\n",
    "                         )\n",
    "    \n",
    "    # predict\n",
    "    preds_valid = model_xgb.predict(dmx_valid)\n",
    "    preds_test = model_xgb.predict(dmx_test)\n",
    "    preds_skf_test.append(preds_test)\n",
    "    dt_preds_test.append(pd.DataFrame({\"ID\": X_test_transform.ID\n",
    "                                      , \"preds_y_\" + str(i): preds_test}))\n",
    "    # score\n",
    "    score_skf_valid = r2_score(y_valid_transform, preds_valid)\n",
    "    print('Fold %d: Score %f'%(i, score_skf_valid))\n",
    "    score_skf.append(score_skf_valid)\n",
    "\n",
    "# predict test\n",
    "preds_test = np.sum(np.transpose(np.multiply(np.transpose(np.array(preds_skf_test)), np.array(score_skf))), axis = 0) / np.sum(score_skf)\n",
    "# final score\n",
    "score_mean = np.mean(score_skf)\n",
    "score_sd = np.std(score_skf)\n",
    "print('=====================')\n",
    "\n",
    "print('Final Score %f'%score_mean, '; sd %f'%score_sd)\n",
    "\n",
    "print('=====================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  94.80869777,  103.5042506 ,  103.9365935 , ...,  104.10566729,\n",
       "        103.18623221,  104.90216392])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>preds_y_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1228</td>\n",
       "      <td>94.579094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4342</td>\n",
       "      <td>103.428795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5299</td>\n",
       "      <td>103.869469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6774</td>\n",
       "      <td>94.350113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7631</td>\n",
       "      <td>102.450287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID   preds_y_3\n",
       "0  1228   94.579094\n",
       "1  4342  103.428795\n",
       "2  5299  103.869469\n",
       "3  6774   94.350113\n",
       "4  7631  102.450287"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_preds_test[3].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit\n",
    "dt_submit = pd.DataFrame({\"ID\": dt_preds_test[0].ID\n",
    "            , \"y\": preds_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt_submit.to_csv(\"../../data/Mercedes_Benz_Greener_Manufacturing/submission/33_returnToPython_skf8_weightedPrediction_base_features_withTargetMeanOofInsideSkf.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
