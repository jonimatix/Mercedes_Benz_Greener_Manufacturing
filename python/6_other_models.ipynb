{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold, train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin\n",
    "from sklearn.linear_model import ElasticNetCV, LassoLarsCV\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.utils import check_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data\n",
    "dt_model = pd.read_csv(\"../../data/Mercedes_Benz_Greener_Manufacturing/data/dt_all_preprocess.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8418, 1364)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove ohe\n",
    "dt_model_features = dt_model.drop(dt_model.filter(regex = \"Encode_ohe\").columns, axis = 1)\n",
    "dt_model_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X, y, ID\n",
    "X_train_all = dt_model_features.loc[dt_model_features[\"IsTrainTest\"] == \"train\"].drop([\"y\", \"IsTrainTest\"], axis = 1)\n",
    "X_test = dt_model_features.loc[dt_model_features[\"IsTrainTest\"] == \"test\"].drop([\"y\", \"IsTrainTest\"], axis = 1)\n",
    "y_train_all = dt_model_features.loc[dt_model_features[\"IsTrainTest\"] == \"train\"].y.values\n",
    "y_test = dt_model_features.loc[dt_model_features[\"IsTrainTest\"] == \"test\"].y.values\n",
    "ID_train_all = dt_model_features.loc[dt_model_features[\"IsTrainTest\"] == \"train\"].ID.values\n",
    "ID_test = dt_model_features.loc[dt_model_features[\"IsTrainTest\"] == \"test\"].ID.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack\n",
    "class StackingEstimator(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, estimator):\n",
    "        self.estimator = estimator\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        self.estimator.fit(X, y, **fit_params)\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = check_array(X)\n",
    "        X_transformed = np.copy(X)\n",
    "        # add class probabilities as a synthetic feature\n",
    "        if issubclass(self.estimator.__class__, ClassifierMixin) and hasattr(self.estimator, 'predict_proba'):\n",
    "            X_transformed = np.hstack((self.estimator.predict_proba(X), X))\n",
    "\n",
    "        # add class prodiction as a synthetic feature\n",
    "        X_transformed = np.hstack((np.reshape(self.estimator.predict(X), (-1, 1)), X_transformed))\n",
    "\n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_pipeline = make_pipeline(\n",
    "    StackingEstimator(estimator = LassoLarsCV(normalize = True, cv = 5))\n",
    "    , StackingEstimator(estimator = GradientBoostingRegressor(learning_rate = 0.001, loss = \"huber\", max_depth = 3, max_features = 0.55\n",
    "                                                              , min_samples_leaf = 18, min_samples_split = 14, subsample = 0.7))\n",
    "    , LassoLarsCV(cv = 5)\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: Score 0.522337\n",
      "Fold 1: Score 0.634774\n",
      "Fold 2: Score 0.633094\n",
      "Fold 3: Score 0.601006\n",
      "Fold 4: Score 0.554288\n",
      "Fold 5: Score 0.395096\n",
      "Fold 6: Score 0.552692\n",
      "Fold 7: Score 0.582648\n",
      "Fold 8: Score 0.608986\n",
      "Fold 9: Score 0.610909\n",
      "=====================\n",
      "Final Score 0.569583\n",
      "=====================\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "# bin\n",
    "bin_y = pd.qcut(y_train_all, k, labels = [i for i in range(1, k + 1)]).astype(\"int64\")\n",
    "# stratified kfold\n",
    "skf = StratifiedKFold(n_splits = k, shuffle = True, random_state = 888)\n",
    "\n",
    "score_skf_valid = 0\n",
    "score_skf = 0\n",
    "preds_skf_test = []\n",
    "for i, (ind_train, ind_valid) in enumerate(skf.split(X_train_all, bin_y)):\n",
    "    # X, y\n",
    "    X_train, X_valid = X_train_all.iloc[ind_train], X_train_all.iloc[ind_valid]\n",
    "    y_train, y_valid = y_train_all[ind_train], y_train_all[ind_valid]\n",
    "    \n",
    "    stacked_pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    preds_valid = stacked_pipeline.predict(X_valid)\n",
    "    score_skf_valid = r2_score(y_valid, preds_valid)\n",
    "    print('Fold %d: Score %f'%(i, score_skf_valid))\n",
    "\n",
    "    score_skf += score_skf_valid\n",
    "\n",
    "score_skf /= k\n",
    "print('=====================')\n",
    "\n",
    "print( 'Final Score %f'%score_skf)\n",
    "\n",
    "print('=====================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  79.90089004,   94.10677142,   79.28796135,   79.37421186,\n",
       "        111.68541258,   94.06358613,  111.68541258,   94.09354929,\n",
       "        115.27120233,   94.23010788])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict\n",
    "y_test = stacked_pipeline.predict(X_test)\n",
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# submit\n",
    "dt_submit = pd.DataFrame({\"ID\": ID_test, \"y\": y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt_submit.to_csv(\"../../data/Mercedes_Benz_Greener_Manufacturing/submission/16_Lasso_GBR_Lasso.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
