{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Keras is a deep learning library that wraps the efficient numerical libraries Theano and TensorFlow.\n",
    "# It provides a clean and simple API that allows you to define and evaluate deep learning models in just a few lines of code.from keras.models import Sequential, load_model\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# define custom R2 metrics for Keras backend\n",
    "from keras import backend as K\n",
    "# to tune the NN\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.regularizers import l2\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define path to save model\n",
    "import os\n",
    "model_path = \"../../data/Mercedes_Benz_Greener_Manufacturing/model/model_nn.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data\n",
    "dt_model = pd.read_csv(\"../../data/Mercedes_Benz_Greener_Manufacturing/data/dt_all_preprocess.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove ohe\n",
    "# dt_model = dt_model.drop(dt_model.filter(regex = \"Encode_ohe\").columns, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# r_2 for nn\n",
    "def r2_keras(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square( y_true - y_pred )) \n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) ) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X, y, ID\n",
    "X_train_all = dt_model.loc[dt_model[\"IsTrainTest\"] == \"train\"].drop([\"ID\", \"y\", \"IsTrainTest\"], axis = 1).as_matrix()\n",
    "X_test = dt_model.loc[dt_model[\"IsTrainTest\"] == \"test\"].drop([\"ID\", \"y\", \"IsTrainTest\"], axis = 1).as_matrix()\n",
    "y_train_all = dt_model.loc[dt_model[\"IsTrainTest\"] == \"train\"].y.values\n",
    "y_test = dt_model.loc[dt_model[\"IsTrainTest\"] == \"test\"].y.values\n",
    "ID_train_all = dt_model.loc[dt_model[\"IsTrainTest\"] == \"train\"].ID.values\n",
    "ID_test = dt_model.loc[dt_model[\"IsTrainTest\"] == \"test\"].ID.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras\n",
    "def model(dropout_level = 0.25, activation = 'tanh'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1024, input_dim=input_dims, kernel_initializer=\"he_normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dropout(dropout_level))\n",
    "    \n",
    "    model.add(Dense(1024, kernel_initializer=\"he_normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dropout(dropout_level))\n",
    "    \n",
    "    model.add(Dense(1024, kernel_initializer=\"he_normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dropout(dropout_level))\n",
    "    \n",
    "    model.add(Dense(1024, kernel_initializer=\"he_normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dropout(dropout_level))\n",
    "    \n",
    "    model.add(Dense(1024, kernel_initializer=\"he_normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dropout(dropout_level))\n",
    "    \n",
    "    model.add(Dense(768, kernel_initializer=\"he_normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dropout(dropout_level))\n",
    "    \n",
    "    model.add(Dense(768, kernel_initializer=\"he_normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dropout(dropout_level))\n",
    "    \n",
    "    model.add(Dense(768, kernel_initializer=\"he_normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dropout(dropout_level))\n",
    "\n",
    "    model.add(Dense(768, kernel_initializer=\"he_normal\", kernel_regularizer = l2(1.e-5)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dropout(dropout_level))\n",
    "    \n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "    model.compile(loss = \"mean_squared_error\", # one may use 'mean_absolute_error' as alternative\n",
    "                  optimizer = \"adam\",\n",
    "                  metrics = [r2_keras, \"accuracy\"] # you can add several if needed\n",
    "                 )\n",
    "    \n",
    "    # Visualize NN architecture\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dims = X_train_all.shape[1]\n",
    "estimator = KerasRegressor(\n",
    "    build_fn = model, \n",
    "    nb_epoch = 300, \n",
    "    batch_size = 35,\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor = 'val_loss', \n",
    "        patience = 20,\n",
    "        verbose = 1),\n",
    "    ModelCheckpoint(\n",
    "        model_path, \n",
    "        monitor = 'val_loss', \n",
    "        save_best_only = True, \n",
    "        verbose = 0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1024)              1610752   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 768)               787200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 768)               3072      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 768)               590592    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 768)               3072      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 768)               590592    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 768)               3072      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 768)               590592    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 768)               3072      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 769       \n",
      "=================================================================\n",
      "Total params: 8,401,665\n",
      "Trainable params: 8,385,281\n",
      "Non-trainable params: 16,384\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 3367 samples, validate on 842 samples\n",
      "Epoch 1/500\n",
      "3s - loss: 9838.8905 - r2_keras: -6.5541e+01 - acc: 0.0000e+00 - val_loss: 8258.0685 - val_r2_keras: -5.8190e+01 - val_acc: 0.0000e+00\n",
      "Epoch 2/500\n",
      "2s - loss: 7804.9271 - r2_keras: -5.1661e+01 - acc: 0.0000e+00 - val_loss: 5326.1897 - val_r2_keras: -3.7307e+01 - val_acc: 0.0000e+00\n",
      "Epoch 3/500\n",
      "2s - loss: 5514.9716 - r2_keras: -3.6766e+01 - acc: 0.0000e+00 - val_loss: 3963.4737 - val_r2_keras: -2.7240e+01 - val_acc: 0.0000e+00\n",
      "Epoch 4/500\n",
      "1s - loss: 3208.0579 - r2_keras: -2.0478e+01 - acc: 0.0000e+00 - val_loss: 1804.1333 - val_r2_keras: -1.1919e+01 - val_acc: 0.0000e+00\n",
      "Epoch 5/500\n",
      "2s - loss: 1827.0748 - r2_keras: -1.1367e+01 - acc: 2.9700e-04 - val_loss: 1227.9640 - val_r2_keras: -7.6165e+00 - val_acc: 0.0000e+00\n",
      "Epoch 6/500\n",
      "2s - loss: 1256.0308 - r2_keras: -7.6178e+00 - acc: 2.9700e-04 - val_loss: 750.5997 - val_r2_keras: -4.2544e+00 - val_acc: 0.0000e+00\n",
      "Epoch 7/500\n",
      "1s - loss: 902.7057 - r2_keras: -4.9068e+00 - acc: 5.9400e-04 - val_loss: 974.1922 - val_r2_keras: -5.9236e+00 - val_acc: 0.0000e+00\n",
      "Epoch 8/500\n",
      "2s - loss: 754.6135 - r2_keras: -4.1758e+00 - acc: 2.9700e-04 - val_loss: 484.5863 - val_r2_keras: -2.4457e+00 - val_acc: 0.0000e+00\n",
      "Epoch 9/500\n",
      "2s - loss: 502.6656 - r2_keras: -2.3716e+00 - acc: 5.9400e-04 - val_loss: 370.4695 - val_r2_keras: -1.6542e+00 - val_acc: 0.0000e+00\n",
      "Epoch 10/500\n",
      "2s - loss: 413.1445 - r2_keras: -1.7385e+00 - acc: 0.0000e+00 - val_loss: 213.7970 - val_r2_keras: -4.6602e-01 - val_acc: 0.0000e+00\n",
      "Epoch 11/500\n",
      "2s - loss: 382.7904 - r2_keras: -1.5821e+00 - acc: 2.9700e-04 - val_loss: 361.2285 - val_r2_keras: -1.4784e+00 - val_acc: 0.0000e+00\n",
      "Epoch 12/500\n",
      "2s - loss: 310.1173 - r2_keras: -1.0389e+00 - acc: 0.0000e+00 - val_loss: 165.8929 - val_r2_keras: -1.4243e-01 - val_acc: 0.0000e+00\n",
      "Epoch 13/500\n",
      "2s - loss: 237.0719 - r2_keras: -5.6619e-01 - acc: 2.9700e-04 - val_loss: 159.1866 - val_r2_keras: -1.1762e-01 - val_acc: 0.0000e+00\n",
      "Epoch 14/500\n",
      "2s - loss: 237.4961 - r2_keras: -5.1061e-01 - acc: 2.9700e-04 - val_loss: 124.8786 - val_r2_keras: 0.1586 - val_acc: 0.0000e+00\n",
      "Epoch 15/500\n",
      "2s - loss: 195.3690 - r2_keras: -2.4625e-01 - acc: 5.9400e-04 - val_loss: 120.8824 - val_r2_keras: 0.1711 - val_acc: 0.0000e+00\n",
      "Epoch 16/500\n",
      "2s - loss: 186.1440 - r2_keras: -1.9457e-01 - acc: 0.0000e+00 - val_loss: 110.7504 - val_r2_keras: 0.2604 - val_acc: 0.0012\n",
      "Epoch 17/500\n",
      "1s - loss: 187.5272 - r2_keras: -2.1049e-01 - acc: 0.0012 - val_loss: 129.4481 - val_r2_keras: 0.1186 - val_acc: 0.0000e+00\n",
      "Epoch 18/500\n",
      "2s - loss: 170.4379 - r2_keras: -8.8938e-02 - acc: 5.9400e-04 - val_loss: 93.3815 - val_r2_keras: 0.3837 - val_acc: 0.0012\n",
      "Epoch 19/500\n",
      "2s - loss: 163.9926 - r2_keras: -9.9072e-02 - acc: 5.9400e-04 - val_loss: 102.7983 - val_r2_keras: 0.3417 - val_acc: 0.0012\n",
      "Epoch 20/500\n",
      "2s - loss: 154.1788 - r2_keras: 0.0150 - acc: 2.9700e-04 - val_loss: 80.4710 - val_r2_keras: 0.4765 - val_acc: 0.0000e+00\n",
      "Epoch 21/500\n",
      "1s - loss: 155.9393 - r2_keras: 0.0085 - acc: 5.9400e-04 - val_loss: 94.1579 - val_r2_keras: 0.3662 - val_acc: 0.0012\n",
      "Epoch 22/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1s - loss: 147.4221 - r2_keras: 0.0787 - acc: 0.0000e+00 - val_loss: 85.8081 - val_r2_keras: 0.4398 - val_acc: 0.0024\n",
      "Epoch 23/500\n",
      "1s - loss: 200.6510 - r2_keras: -2.0911e-01 - acc: 2.9700e-04 - val_loss: 149.7524 - val_r2_keras: -4.0358e-03 - val_acc: 0.0000e+00\n",
      "Epoch 24/500\n",
      "2s - loss: 152.7059 - r2_keras: 0.0302 - acc: 0.0000e+00 - val_loss: 76.0262 - val_r2_keras: 0.5054 - val_acc: 0.0012\n",
      "Epoch 25/500\n",
      "1s - loss: 139.3512 - r2_keras: 0.1325 - acc: 2.9700e-04 - val_loss: 79.6005 - val_r2_keras: 0.4900 - val_acc: 0.0012\n",
      "Epoch 26/500\n",
      "1s - loss: 131.4802 - r2_keras: 0.1842 - acc: 2.9700e-04 - val_loss: 89.7833 - val_r2_keras: 0.4031 - val_acc: 0.0012\n",
      "Epoch 27/500\n",
      "2s - loss: 135.3313 - r2_keras: 0.1506 - acc: 2.9700e-04 - val_loss: 69.5847 - val_r2_keras: 0.5526 - val_acc: 0.0012\n",
      "Epoch 28/500\n",
      "1s - loss: 133.8252 - r2_keras: 0.1755 - acc: 0.0000e+00 - val_loss: 70.2465 - val_r2_keras: 0.5472 - val_acc: 0.0000e+00\n",
      "Epoch 29/500\n",
      "2s - loss: 124.5017 - r2_keras: 0.2275 - acc: 5.9400e-04 - val_loss: 82.2266 - val_r2_keras: 0.4703 - val_acc: 0.0000e+00\n",
      "Epoch 30/500\n",
      "1s - loss: 132.0033 - r2_keras: 0.1756 - acc: 5.9400e-04 - val_loss: 73.1596 - val_r2_keras: 0.5310 - val_acc: 0.0012\n",
      "Epoch 31/500\n",
      "1s - loss: 141.4974 - r2_keras: 0.1123 - acc: 2.9700e-04 - val_loss: 91.8722 - val_r2_keras: 0.3982 - val_acc: 0.0012\n",
      "Epoch 32/500\n",
      "1s - loss: 129.0650 - r2_keras: 0.1952 - acc: 0.0000e+00 - val_loss: 83.8199 - val_r2_keras: 0.4600 - val_acc: 0.0000e+00\n",
      "Epoch 33/500\n",
      "2s - loss: 133.6270 - r2_keras: 0.1586 - acc: 2.9700e-04 - val_loss: 75.0568 - val_r2_keras: 0.5183 - val_acc: 0.0000e+00\n",
      "Epoch 34/500\n",
      "2s - loss: 119.4187 - r2_keras: 0.2574 - acc: 0.0000e+00 - val_loss: 73.8533 - val_r2_keras: 0.5156 - val_acc: 0.0000e+00\n",
      "Epoch 35/500\n",
      "2s - loss: 124.0626 - r2_keras: 0.2340 - acc: 0.0000e+00 - val_loss: 70.6771 - val_r2_keras: 0.5472 - val_acc: 0.0000e+00\n",
      "Epoch 36/500\n",
      "1s - loss: 125.4287 - r2_keras: 0.2151 - acc: 5.9400e-04 - val_loss: 69.9209 - val_r2_keras: 0.5483 - val_acc: 0.0000e+00\n",
      "Epoch 37/500\n",
      "2s - loss: 115.6388 - r2_keras: 0.2886 - acc: 8.9100e-04 - val_loss: 69.1616 - val_r2_keras: 0.5556 - val_acc: 0.0024\n",
      "Epoch 38/500\n",
      "1s - loss: 122.0938 - r2_keras: 0.2404 - acc: 2.9700e-04 - val_loss: 80.1027 - val_r2_keras: 0.4875 - val_acc: 0.0000e+00\n",
      "Epoch 39/500\n",
      "2s - loss: 124.5178 - r2_keras: 0.2269 - acc: 2.9700e-04 - val_loss: 66.2061 - val_r2_keras: 0.5784 - val_acc: 0.0036\n",
      "Epoch 40/500\n",
      "1s - loss: 114.8280 - r2_keras: 0.2827 - acc: 0.0000e+00 - val_loss: 71.9395 - val_r2_keras: 0.5279 - val_acc: 0.0000e+00\n",
      "Epoch 41/500\n",
      "2s - loss: 116.3505 - r2_keras: 0.2723 - acc: 0.0012 - val_loss: 69.5185 - val_r2_keras: 0.5379 - val_acc: 0.0012\n",
      "Epoch 42/500\n",
      "1s - loss: 111.8601 - r2_keras: 0.3010 - acc: 0.0000e+00 - val_loss: 67.4790 - val_r2_keras: 0.5716 - val_acc: 0.0000e+00\n",
      "Epoch 43/500\n",
      "2s - loss: 112.1204 - r2_keras: 0.3053 - acc: 0.0000e+00 - val_loss: 70.1634 - val_r2_keras: 0.5402 - val_acc: 0.0012\n",
      "Epoch 44/500\n",
      "1s - loss: 117.1863 - r2_keras: 0.2680 - acc: 0.0012 - val_loss: 78.1840 - val_r2_keras: 0.4578 - val_acc: 0.0012\n",
      "Epoch 45/500\n",
      "2s - loss: 113.9059 - r2_keras: 0.2928 - acc: 2.9700e-04 - val_loss: 66.1748 - val_r2_keras: 0.5753 - val_acc: 0.0012\n",
      "Epoch 46/500\n",
      "1s - loss: 111.1184 - r2_keras: 0.3125 - acc: 8.9100e-04 - val_loss: 69.5628 - val_r2_keras: 0.5487 - val_acc: 0.0012\n",
      "Epoch 47/500\n",
      "2s - loss: 111.7798 - r2_keras: 0.3066 - acc: 2.9700e-04 - val_loss: 79.4608 - val_r2_keras: 0.4624 - val_acc: 0.0000e+00\n",
      "Epoch 48/500\n",
      "2s - loss: 108.8052 - r2_keras: 0.3119 - acc: 2.9700e-04 - val_loss: 83.1389 - val_r2_keras: 0.4200 - val_acc: 0.0000e+00\n",
      "Epoch 49/500\n",
      "2s - loss: 113.3684 - r2_keras: 0.3025 - acc: 2.9700e-04 - val_loss: 75.2474 - val_r2_keras: 0.4785 - val_acc: 0.0000e+00\n",
      "Epoch 50/500\n",
      "1s - loss: 104.5132 - r2_keras: 0.3505 - acc: 2.9700e-04 - val_loss: 81.4988 - val_r2_keras: 0.4174 - val_acc: 0.0000e+00\n",
      "Epoch 51/500\n",
      "1s - loss: 113.8672 - r2_keras: 0.2805 - acc: 2.9700e-04 - val_loss: 72.8964 - val_r2_keras: 0.5111 - val_acc: 0.0024\n",
      "Epoch 52/500\n",
      "1s - loss: 111.9186 - r2_keras: 0.3100 - acc: 2.9700e-04 - val_loss: 76.0347 - val_r2_keras: 0.5214 - val_acc: 0.0000e+00\n",
      "Epoch 53/500\n",
      "1s - loss: 110.5819 - r2_keras: 0.3208 - acc: 0.0012 - val_loss: 75.6576 - val_r2_keras: 0.4951 - val_acc: 0.0012\n",
      "Epoch 54/500\n",
      "2s - loss: 105.4074 - r2_keras: 0.3418 - acc: 2.9700e-04 - val_loss: 67.8132 - val_r2_keras: 0.5623 - val_acc: 0.0024\n",
      "Epoch 55/500\n",
      "1s - loss: 107.3399 - r2_keras: 0.3259 - acc: 8.9100e-04 - val_loss: 68.4999 - val_r2_keras: 0.5581 - val_acc: 0.0012\n",
      "Epoch 56/500\n",
      "1s - loss: 105.3753 - r2_keras: 0.3530 - acc: 8.9100e-04 - val_loss: 74.0530 - val_r2_keras: 0.5240 - val_acc: 0.0012\n",
      "Epoch 57/500\n",
      "2s - loss: 107.1847 - r2_keras: 0.3392 - acc: 5.9400e-04 - val_loss: 71.2975 - val_r2_keras: 0.5387 - val_acc: 0.0000e+00\n",
      "Epoch 58/500\n",
      "2s - loss: 108.8729 - r2_keras: 0.3270 - acc: 2.9700e-04 - val_loss: 69.4797 - val_r2_keras: 0.5538 - val_acc: 0.0000e+00\n",
      "Epoch 59/500\n",
      "2s - loss: 105.0925 - r2_keras: 0.3493 - acc: 2.9700e-04 - val_loss: 64.1721 - val_r2_keras: 0.5985 - val_acc: 0.0000e+00\n",
      "Epoch 60/500\n",
      "2s - loss: 106.4683 - r2_keras: 0.3389 - acc: 0.0000e+00 - val_loss: 69.5489 - val_r2_keras: 0.5546 - val_acc: 0.0012\n",
      "Epoch 61/500\n",
      "2s - loss: 107.2372 - r2_keras: 0.3291 - acc: 2.9700e-04 - val_loss: 78.4062 - val_r2_keras: 0.4957 - val_acc: 0.0000e+00\n",
      "Epoch 62/500\n",
      "2s - loss: 103.0696 - r2_keras: 0.3548 - acc: 2.9700e-04 - val_loss: 65.3923 - val_r2_keras: 0.5810 - val_acc: 0.0012\n",
      "Epoch 63/500\n",
      "2s - loss: 106.2469 - r2_keras: 0.3412 - acc: 2.9700e-04 - val_loss: 66.7113 - val_r2_keras: 0.5756 - val_acc: 0.0024\n",
      "Epoch 64/500\n",
      "1s - loss: 103.7744 - r2_keras: 0.3447 - acc: 2.9700e-04 - val_loss: 71.7863 - val_r2_keras: 0.5511 - val_acc: 0.0012\n",
      "Epoch 65/500\n",
      "1s - loss: 101.1932 - r2_keras: 0.3757 - acc: 2.9700e-04 - val_loss: 71.0181 - val_r2_keras: 0.5445 - val_acc: 0.0012\n",
      "Epoch 66/500\n",
      "2s - loss: 101.4096 - r2_keras: 0.3634 - acc: 5.9400e-04 - val_loss: 66.7883 - val_r2_keras: 0.5734 - val_acc: 0.0000e+00\n",
      "Epoch 67/500\n",
      "2s - loss: 98.9095 - r2_keras: 0.3904 - acc: 8.9100e-04 - val_loss: 73.4516 - val_r2_keras: 0.5353 - val_acc: 0.0000e+00\n",
      "Epoch 68/500\n",
      "1s - loss: 104.5101 - r2_keras: 0.3495 - acc: 2.9700e-04 - val_loss: 78.2116 - val_r2_keras: 0.4886 - val_acc: 0.0000e+00\n",
      "Epoch 69/500\n",
      "2s - loss: 100.8251 - r2_keras: 0.3710 - acc: 0.0012 - val_loss: 69.5474 - val_r2_keras: 0.5547 - val_acc: 0.0024\n",
      "Epoch 70/500\n",
      "1s - loss: 96.2736 - r2_keras: 0.4066 - acc: 5.9400e-04 - val_loss: 66.2892 - val_r2_keras: 0.5742 - val_acc: 0.0000e+00\n",
      "Epoch 71/500\n",
      "1s - loss: 104.0489 - r2_keras: 0.3575 - acc: 0.0012 - val_loss: 75.9434 - val_r2_keras: 0.5033 - val_acc: 0.0000e+00\n",
      "Epoch 72/500\n",
      "1s - loss: 95.6181 - r2_keras: 0.4038 - acc: 2.9700e-04 - val_loss: 72.2964 - val_r2_keras: 0.5337 - val_acc: 0.0000e+00\n",
      "Epoch 73/500\n",
      "1s - loss: 101.3424 - r2_keras: 0.3661 - acc: 0.0000e+00 - val_loss: 74.6446 - val_r2_keras: 0.5119 - val_acc: 0.0012\n",
      "Epoch 74/500\n",
      "2s - loss: 105.6982 - r2_keras: 0.3501 - acc: 2.9700e-04 - val_loss: 66.3280 - val_r2_keras: 0.5775 - val_acc: 0.0000e+00\n",
      "Epoch 75/500\n",
      "2s - loss: 97.2292 - r2_keras: 0.4026 - acc: 2.9700e-04 - val_loss: 70.1974 - val_r2_keras: 0.5482 - val_acc: 0.0000e+00\n",
      "Epoch 76/500\n",
      "1s - loss: 95.7180 - r2_keras: 0.3976 - acc: 5.9400e-04 - val_loss: 68.4950 - val_r2_keras: 0.5632 - val_acc: 0.0012\n",
      "Epoch 77/500\n",
      "1s - loss: 97.0822 - r2_keras: 0.3938 - acc: 8.9100e-04 - val_loss: 73.5290 - val_r2_keras: 0.5289 - val_acc: 0.0000e+00\n",
      "Epoch 78/500\n",
      "2s - loss: 98.5523 - r2_keras: 0.3826 - acc: 8.9100e-04 - val_loss: 74.0581 - val_r2_keras: 0.5287 - val_acc: 0.0000e+00\n",
      "Epoch 79/500\n",
      "2s - loss: 102.7836 - r2_keras: 0.3800 - acc: 2.9700e-04 - val_loss: 68.0914 - val_r2_keras: 0.5676 - val_acc: 0.0012\n",
      "Epoch 80/500\n",
      "2s - loss: 105.4434 - r2_keras: 0.3532 - acc: 2.9700e-04 - val_loss: 69.3593 - val_r2_keras: 0.5595 - val_acc: 0.0012\n",
      "Epoch 00079: early stopping\n",
      "Fold 0: Score 0.579863\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 1024)              1610752   \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 768)               787200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 768)               3072      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 768)               590592    \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 768)               3072      \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 768)               590592    \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 768)               3072      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 768)               590592    \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 768)               3072      \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 769       \n",
      "=================================================================\n",
      "Total params: 8,401,665\n",
      "Trainable params: 8,385,281\n",
      "Non-trainable params: 16,384\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3367 samples, validate on 842 samples\n",
      "Epoch 1/500\n",
      "2s - loss: 9769.7696 - r2_keras: -6.9711e+01 - acc: 0.0000e+00 - val_loss: 7927.3973 - val_r2_keras: -4.5701e+01 - val_acc: 0.0000e+00\n",
      "Epoch 2/500\n",
      "1s - loss: 7367.5559 - r2_keras: -5.1636e+01 - acc: 0.0000e+00 - val_loss: 4627.0102 - val_r2_keras: -2.6072e+01 - val_acc: 0.0000e+00\n",
      "Epoch 3/500\n",
      "1s - loss: 4808.6203 - r2_keras: -3.3196e+01 - acc: 0.0000e+00 - val_loss: 2539.5953 - val_r2_keras: -1.3715e+01 - val_acc: 0.0000e+00\n",
      "Epoch 4/500\n",
      "1s - loss: 2927.1137 - r2_keras: -1.9516e+01 - acc: 0.0000e+00 - val_loss: 1278.5499 - val_r2_keras: -6.2589e+00 - val_acc: 0.0000e+00\n",
      "Epoch 5/500\n",
      "1s - loss: 2037.4841 - r2_keras: -1.3717e+01 - acc: 2.9700e-04 - val_loss: 1116.7127 - val_r2_keras: -5.2830e+00 - val_acc: 0.0000e+00\n",
      "Epoch 6/500\n",
      "1s - loss: 1124.1732 - r2_keras: -6.9715e+00 - acc: 0.0000e+00 - val_loss: 762.8062 - val_r2_keras: -3.2999e+00 - val_acc: 0.0024\n",
      "Epoch 7/500\n",
      "2s - loss: 774.0754 - r2_keras: -4.4590e+00 - acc: 2.9700e-04 - val_loss: 493.2476 - val_r2_keras: -1.7523e+00 - val_acc: 0.0000e+00\n",
      "Epoch 8/500\n",
      "1s - loss: 544.6749 - r2_keras: -2.7682e+00 - acc: 2.9700e-04 - val_loss: 383.2438 - val_r2_keras: -9.8189e-01 - val_acc: 0.0000e+00\n",
      "Epoch 9/500\n",
      "1s - loss: 397.4102 - r2_keras: -1.7724e+00 - acc: 5.9400e-04 - val_loss: 378.1028 - val_r2_keras: -1.0133e+00 - val_acc: 0.0000e+00\n",
      "Epoch 10/500\n",
      "2s - loss: 344.4902 - r2_keras: -1.4180e+00 - acc: 2.9700e-04 - val_loss: 272.5847 - val_r2_keras: -4.1189e-01 - val_acc: 0.0012\n",
      "Epoch 11/500\n",
      "1s - loss: 218.7717 - r2_keras: -5.3138e-01 - acc: 2.9700e-04 - val_loss: 214.6950 - val_r2_keras: -5.4151e-02 - val_acc: 0.0000e+00\n",
      "Epoch 12/500\n",
      "1s - loss: 216.8569 - r2_keras: -4.9820e-01 - acc: 8.9100e-04 - val_loss: 189.0525 - val_r2_keras: 0.0995 - val_acc: 0.0000e+00\n",
      "Epoch 13/500\n",
      "2s - loss: 198.8327 - r2_keras: -3.6822e-01 - acc: 2.9700e-04 - val_loss: 183.2338 - val_r2_keras: 0.1308 - val_acc: 0.0000e+00\n",
      "Epoch 14/500\n",
      "1s - loss: 165.7940 - r2_keras: -1.7662e-01 - acc: 2.9700e-04 - val_loss: 141.7826 - val_r2_keras: 0.3725 - val_acc: 0.0024\n",
      "Epoch 15/500\n",
      "2s - loss: 144.2103 - r2_keras: -7.1150e-04 - acc: 0.0012 - val_loss: 166.8014 - val_r2_keras: 0.2490 - val_acc: 0.0012\n",
      "Epoch 16/500\n",
      "2s - loss: 125.4192 - r2_keras: 0.1338 - acc: 5.9400e-04 - val_loss: 175.0469 - val_r2_keras: 0.1983 - val_acc: 0.0012\n",
      "Epoch 17/500\n",
      "2s - loss: 141.5732 - r2_keras: 0.0182 - acc: 5.9400e-04 - val_loss: 153.1008 - val_r2_keras: 0.2995 - val_acc: 0.0000e+00\n",
      "Epoch 18/500\n",
      "1s - loss: 143.9289 - r2_keras: -5.9306e-03 - acc: 8.9100e-04 - val_loss: 136.5152 - val_r2_keras: 0.4009 - val_acc: 0.0012\n",
      "Epoch 19/500\n",
      "1s - loss: 122.5506 - r2_keras: 0.1569 - acc: 0.0000e+00 - val_loss: 135.0059 - val_r2_keras: 0.3909 - val_acc: 0.0000e+00\n",
      "Epoch 20/500\n",
      "1s - loss: 115.2473 - r2_keras: 0.2107 - acc: 2.9700e-04 - val_loss: 133.2019 - val_r2_keras: 0.4270 - val_acc: 0.0012\n",
      "Epoch 21/500\n",
      "1s - loss: 118.9457 - r2_keras: 0.1583 - acc: 0.0000e+00 - val_loss: 132.6110 - val_r2_keras: 0.3942 - val_acc: 0.0012\n",
      "Epoch 22/500\n",
      "2s - loss: 113.8492 - r2_keras: 0.2063 - acc: 2.9700e-04 - val_loss: 136.2362 - val_r2_keras: 0.3917 - val_acc: 0.0000e+00\n",
      "Epoch 23/500\n",
      "2s - loss: 109.2313 - r2_keras: 0.2584 - acc: 0.0000e+00 - val_loss: 125.1248 - val_r2_keras: 0.4618 - val_acc: 0.0000e+00\n",
      "Epoch 24/500\n",
      "2s - loss: 109.2040 - r2_keras: 0.2424 - acc: 2.9700e-04 - val_loss: 144.5583 - val_r2_keras: 0.3652 - val_acc: 0.0012\n",
      "Epoch 25/500\n",
      "2s - loss: 105.5011 - r2_keras: 0.2710 - acc: 2.9700e-04 - val_loss: 129.4890 - val_r2_keras: 0.4400 - val_acc: 0.0012\n",
      "Epoch 26/500\n",
      "1s - loss: 106.6149 - r2_keras: 0.2643 - acc: 8.9100e-04 - val_loss: 127.5185 - val_r2_keras: 0.4523 - val_acc: 0.0012\n",
      "Epoch 27/500\n",
      "2s - loss: 107.9296 - r2_keras: 0.2581 - acc: 2.9700e-04 - val_loss: 132.8547 - val_r2_keras: 0.4098 - val_acc: 0.0012\n",
      "Epoch 28/500\n",
      "2s - loss: 107.4207 - r2_keras: 0.2567 - acc: 2.9700e-04 - val_loss: 136.6598 - val_r2_keras: 0.4072 - val_acc: 0.0012\n",
      "Epoch 29/500\n",
      "2s - loss: 100.5762 - r2_keras: 0.3184 - acc: 2.9700e-04 - val_loss: 140.9070 - val_r2_keras: 0.3797 - val_acc: 0.0012\n",
      "Epoch 30/500\n",
      "1s - loss: 102.6223 - r2_keras: 0.2840 - acc: 2.9700e-04 - val_loss: 126.9767 - val_r2_keras: 0.4440 - val_acc: 0.0012\n",
      "Epoch 31/500\n",
      "1s - loss: 105.2165 - r2_keras: 0.2692 - acc: 5.9400e-04 - val_loss: 126.2562 - val_r2_keras: 0.4554 - val_acc: 0.0000e+00\n",
      "Epoch 32/500\n",
      "1s - loss: 103.2223 - r2_keras: 0.2958 - acc: 2.9700e-04 - val_loss: 125.0720 - val_r2_keras: 0.4694 - val_acc: 0.0000e+00\n",
      "Epoch 33/500\n",
      "2s - loss: 102.0639 - r2_keras: 0.3000 - acc: 2.9700e-04 - val_loss: 119.5103 - val_r2_keras: 0.4940 - val_acc: 0.0000e+00\n",
      "Epoch 34/500\n",
      "1s - loss: 104.6565 - r2_keras: 0.2731 - acc: 8.9100e-04 - val_loss: 128.1352 - val_r2_keras: 0.4470 - val_acc: 0.0000e+00\n",
      "Epoch 35/500\n",
      "2s - loss: 93.3583 - r2_keras: 0.3654 - acc: 5.9400e-04 - val_loss: 131.9536 - val_r2_keras: 0.4267 - val_acc: 0.0024\n",
      "Epoch 36/500\n",
      "2s - loss: 93.9749 - r2_keras: 0.3496 - acc: 2.9700e-04 - val_loss: 122.5877 - val_r2_keras: 0.4786 - val_acc: 0.0012\n",
      "Epoch 37/500\n",
      "2s - loss: 95.9849 - r2_keras: 0.3340 - acc: 0.0000e+00 - val_loss: 125.2438 - val_r2_keras: 0.4650 - val_acc: 0.0024\n",
      "Epoch 38/500\n",
      "2s - loss: 97.9780 - r2_keras: 0.3224 - acc: 0.0012 - val_loss: 123.5167 - val_r2_keras: 0.4575 - val_acc: 0.0012\n",
      "Epoch 39/500\n",
      "1s - loss: 90.1926 - r2_keras: 0.3847 - acc: 2.9700e-04 - val_loss: 125.9349 - val_r2_keras: 0.4627 - val_acc: 0.0000e+00\n",
      "Epoch 40/500\n",
      "1s - loss: 86.4928 - r2_keras: 0.4109 - acc: 8.9100e-04 - val_loss: 130.7149 - val_r2_keras: 0.4312 - val_acc: 0.0000e+00\n",
      "Epoch 41/500\n",
      "2s - loss: 102.3696 - r2_keras: 0.2979 - acc: 0.0000e+00 - val_loss: 125.6694 - val_r2_keras: 0.4640 - val_acc: 0.0000e+00\n",
      "Epoch 42/500\n",
      "2s - loss: 92.0398 - r2_keras: 0.3651 - acc: 0.0000e+00 - val_loss: 129.0463 - val_r2_keras: 0.4531 - val_acc: 0.0000e+00\n",
      "Epoch 43/500\n",
      "2s - loss: 98.5797 - r2_keras: 0.3220 - acc: 0.0000e+00 - val_loss: 133.8798 - val_r2_keras: 0.4232 - val_acc: 0.0036\n",
      "Epoch 44/500\n",
      "1s - loss: 99.4872 - r2_keras: 0.3181 - acc: 2.9700e-04 - val_loss: 122.5694 - val_r2_keras: 0.4754 - val_acc: 0.0024\n",
      "Epoch 45/500\n",
      "2s - loss: 89.2636 - r2_keras: 0.3735 - acc: 0.0015 - val_loss: 123.1501 - val_r2_keras: 0.4808 - val_acc: 0.0000e+00\n",
      "Epoch 46/500\n",
      "2s - loss: 92.7029 - r2_keras: 0.3532 - acc: 2.9700e-04 - val_loss: 124.7619 - val_r2_keras: 0.4676 - val_acc: 0.0024\n",
      "Epoch 47/500\n",
      "1s - loss: 93.6330 - r2_keras: 0.3536 - acc: 2.9700e-04 - val_loss: 120.7038 - val_r2_keras: 0.4844 - val_acc: 0.0000e+00\n",
      "Epoch 48/500\n",
      "1s - loss: 89.0880 - r2_keras: 0.3844 - acc: 0.0012 - val_loss: 122.8993 - val_r2_keras: 0.4631 - val_acc: 0.0000e+00\n",
      "Epoch 49/500\n",
      "1s - loss: 86.6964 - r2_keras: 0.4024 - acc: 5.9400e-04 - val_loss: 126.8884 - val_r2_keras: 0.4455 - val_acc: 0.0012\n",
      "Epoch 50/500\n",
      "1s - loss: 86.9541 - r2_keras: 0.4047 - acc: 2.9700e-04 - val_loss: 126.5810 - val_r2_keras: 0.4634 - val_acc: 0.0000e+00\n",
      "Epoch 51/500\n",
      "2s - loss: 87.5175 - r2_keras: 0.3978 - acc: 0.0000e+00 - val_loss: 129.4663 - val_r2_keras: 0.4452 - val_acc: 0.0012\n",
      "Epoch 52/500\n",
      "1s - loss: 88.5831 - r2_keras: 0.3943 - acc: 2.9700e-04 - val_loss: 130.7684 - val_r2_keras: 0.4438 - val_acc: 0.0012\n",
      "Epoch 53/500\n",
      "2s - loss: 86.1480 - r2_keras: 0.4031 - acc: 5.9400e-04 - val_loss: 121.0707 - val_r2_keras: 0.4817 - val_acc: 0.0000e+00\n",
      "Epoch 54/500\n",
      "2s - loss: 86.9345 - r2_keras: 0.4058 - acc: 5.9400e-04 - val_loss: 127.4622 - val_r2_keras: 0.4578 - val_acc: 0.0000e+00\n",
      "Epoch 00053: early stopping\n",
      "Fold 1: Score 0.487781\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 1024)              1610752   \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 768)               787200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 768)               3072      \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 768)               590592    \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 768)               3072      \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 768)               590592    \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 768)               3072      \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 768)               590592    \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 768)               3072      \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 769       \n",
      "=================================================================\n",
      "Total params: 8,401,665\n",
      "Trainable params: 8,385,281\n",
      "Non-trainable params: 16,384\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3367 samples, validate on 842 samples\n",
      "Epoch 1/500\n",
      "2s - loss: 9828.6892 - r2_keras: -6.6012e+01 - acc: 0.0000e+00 - val_loss: 8163.4735 - val_r2_keras: -5.6171e+01 - val_acc: 0.0000e+00\n",
      "Epoch 2/500\n",
      "1s - loss: 7853.9678 - r2_keras: -5.2068e+01 - acc: 0.0000e+00 - val_loss: 4652.1143 - val_r2_keras: -3.1692e+01 - val_acc: 0.0000e+00\n",
      "Epoch 3/500\n",
      "1s - loss: 5690.7834 - r2_keras: -3.7809e+01 - acc: 0.0000e+00 - val_loss: 4249.3979 - val_r2_keras: -2.8757e+01 - val_acc: 0.0000e+00\n",
      "Epoch 4/500\n",
      "2s - loss: 3935.9462 - r2_keras: -2.5906e+01 - acc: 0.0000e+00 - val_loss: 3625.0107 - val_r2_keras: -2.4395e+01 - val_acc: 0.0000e+00\n",
      "Epoch 5/500\n",
      "1s - loss: 2682.7732 - r2_keras: -1.7098e+01 - acc: 0.0000e+00 - val_loss: 2367.3918 - val_r2_keras: -1.5817e+01 - val_acc: 0.0000e+00\n",
      "Epoch 6/500\n",
      "1s - loss: 1618.7499 - r2_keras: -1.0096e+01 - acc: 2.9700e-04 - val_loss: 1714.5012 - val_r2_keras: -1.1117e+01 - val_acc: 0.0000e+00\n",
      "Epoch 7/500\n",
      "2s - loss: 1236.2705 - r2_keras: -7.3123e+00 - acc: 2.9700e-04 - val_loss: 1058.5460 - val_r2_keras: -6.4815e+00 - val_acc: 0.0000e+00\n",
      "Epoch 8/500\n",
      "1s - loss: 1044.5736 - r2_keras: -5.9436e+00 - acc: 2.9700e-04 - val_loss: 659.2395 - val_r2_keras: -3.6207e+00 - val_acc: 0.0000e+00\n",
      "Epoch 9/500\n",
      "1s - loss: 786.0745 - r2_keras: -4.3089e+00 - acc: 0.0000e+00 - val_loss: 704.7342 - val_r2_keras: -3.9664e+00 - val_acc: 0.0000e+00\n",
      "Epoch 10/500\n",
      "1s - loss: 624.7485 - r2_keras: -3.1899e+00 - acc: 2.9700e-04 - val_loss: 561.3716 - val_r2_keras: -2.8804e+00 - val_acc: 0.0000e+00\n",
      "Epoch 11/500\n",
      "1s - loss: 489.4070 - r2_keras: -2.2557e+00 - acc: 0.0000e+00 - val_loss: 373.2986 - val_r2_keras: -1.5976e+00 - val_acc: 0.0000e+00\n",
      "Epoch 12/500\n",
      "1s - loss: 407.0623 - r2_keras: -1.7128e+00 - acc: 2.9700e-04 - val_loss: 268.7969 - val_r2_keras: -8.6159e-01 - val_acc: 0.0000e+00\n",
      "Epoch 13/500\n",
      "1s - loss: 365.1294 - r2_keras: -1.3988e+00 - acc: 2.9700e-04 - val_loss: 232.9184 - val_r2_keras: -6.2430e-01 - val_acc: 0.0000e+00\n",
      "Epoch 14/500\n",
      "1s - loss: 354.2179 - r2_keras: -1.4827e+00 - acc: 0.0000e+00 - val_loss: 274.6713 - val_r2_keras: -8.8600e-01 - val_acc: 0.0000e+00\n",
      "Epoch 15/500\n",
      "2s - loss: 287.6700 - r2_keras: -9.0097e-01 - acc: 2.9700e-04 - val_loss: 230.7382 - val_r2_keras: -5.7739e-01 - val_acc: 0.0012\n",
      "Epoch 16/500\n",
      "1s - loss: 251.6530 - r2_keras: -6.1521e-01 - acc: 2.9700e-04 - val_loss: 149.2446 - val_r2_keras: -3.4857e-03 - val_acc: 0.0000e+00\n",
      "Epoch 17/500\n",
      "2s - loss: 252.9033 - r2_keras: -6.8382e-01 - acc: 5.9400e-04 - val_loss: 274.5524 - val_r2_keras: -8.6722e-01 - val_acc: 0.0012\n",
      "Epoch 18/500\n",
      "2s - loss: 282.1192 - r2_keras: -8.9931e-01 - acc: 0.0000e+00 - val_loss: 186.6142 - val_r2_keras: -2.5729e-01 - val_acc: 0.0000e+00\n",
      "Epoch 19/500\n",
      "2s - loss: 211.5902 - r2_keras: -3.7581e-01 - acc: 2.9700e-04 - val_loss: 160.9603 - val_r2_keras: -9.0646e-02 - val_acc: 0.0000e+00\n",
      "Epoch 20/500\n",
      "2s - loss: 186.3746 - r2_keras: -1.7253e-01 - acc: 2.9700e-04 - val_loss: 120.7867 - val_r2_keras: 0.2015 - val_acc: 0.0000e+00\n",
      "Epoch 21/500\n",
      "2s - loss: 163.8611 - r2_keras: -3.7890e-02 - acc: 5.9400e-04 - val_loss: 106.9369 - val_r2_keras: 0.2904 - val_acc: 0.0000e+00\n",
      "Epoch 22/500\n",
      "1s - loss: 151.2545 - r2_keras: 0.0442 - acc: 2.9700e-04 - val_loss: 93.0011 - val_r2_keras: 0.3925 - val_acc: 0.0024\n",
      "Epoch 23/500\n",
      "2s - loss: 149.7785 - r2_keras: 0.0531 - acc: 2.9700e-04 - val_loss: 97.1344 - val_r2_keras: 0.3797 - val_acc: 0.0000e+00\n",
      "Epoch 24/500\n",
      "0s - loss: 169.9434 - r2_keras: -1.0854e-01 - acc: 8.9100e-04 - val_loss: 128.8840 - val_r2_keras: 0.1449 - val_acc: 0.0000e+00\n",
      "Epoch 25/500\n",
      "0s - loss: 139.2866 - r2_keras: 0.1261 - acc: 2.9700e-04 - val_loss: 85.4070 - val_r2_keras: 0.4515 - val_acc: 0.0000e+00\n",
      "Epoch 26/500\n",
      "0s - loss: 147.9356 - r2_keras: 0.0575 - acc: 0.0000e+00 - val_loss: 96.7605 - val_r2_keras: 0.3723 - val_acc: 0.0000e+00\n",
      "Epoch 27/500\n",
      "0s - loss: 128.1777 - r2_keras: 0.1967 - acc: 0.0012 - val_loss: 88.9934 - val_r2_keras: 0.4255 - val_acc: 0.0000e+00\n",
      "Epoch 28/500\n",
      "0s - loss: 119.6246 - r2_keras: 0.2457 - acc: 0.0000e+00 - val_loss: 86.2112 - val_r2_keras: 0.4393 - val_acc: 0.0012\n",
      "Epoch 29/500\n",
      "0s - loss: 121.5218 - r2_keras: 0.2375 - acc: 5.9400e-04 - val_loss: 79.8751 - val_r2_keras: 0.4884 - val_acc: 0.0000e+00\n",
      "Epoch 30/500\n",
      "0s - loss: 121.6599 - r2_keras: 0.2513 - acc: 0.0000e+00 - val_loss: 77.2111 - val_r2_keras: 0.5012 - val_acc: 0.0000e+00\n",
      "Epoch 31/500\n",
      "0s - loss: 119.8198 - r2_keras: 0.2634 - acc: 2.9700e-04 - val_loss: 76.1322 - val_r2_keras: 0.5134 - val_acc: 0.0012\n",
      "Epoch 32/500\n",
      "0s - loss: 116.8232 - r2_keras: 0.2840 - acc: 0.0015 - val_loss: 77.8679 - val_r2_keras: 0.5027 - val_acc: 0.0000e+00\n",
      "Epoch 33/500\n",
      "0s - loss: 123.6253 - r2_keras: 0.2255 - acc: 5.9400e-04 - val_loss: 75.9087 - val_r2_keras: 0.5179 - val_acc: 0.0000e+00\n",
      "Epoch 34/500\n",
      "0s - loss: 122.4863 - r2_keras: 0.2430 - acc: 2.9700e-04 - val_loss: 78.0309 - val_r2_keras: 0.4966 - val_acc: 0.0000e+00\n",
      "Epoch 35/500\n",
      "0s - loss: 111.0930 - r2_keras: 0.3198 - acc: 2.9700e-04 - val_loss: 83.7133 - val_r2_keras: 0.4609 - val_acc: 0.0000e+00\n",
      "Epoch 36/500\n",
      "0s - loss: 121.0383 - r2_keras: 0.2473 - acc: 5.9400e-04 - val_loss: 71.3361 - val_r2_keras: 0.5471 - val_acc: 0.0024\n",
      "Epoch 37/500\n",
      "0s - loss: 117.8067 - r2_keras: 0.2774 - acc: 8.9100e-04 - val_loss: 80.4051 - val_r2_keras: 0.4816 - val_acc: 0.0024\n",
      "Epoch 38/500\n",
      "0s - loss: 116.7028 - r2_keras: 0.2754 - acc: 5.9400e-04 - val_loss: 70.8401 - val_r2_keras: 0.5504 - val_acc: 0.0012\n",
      "Epoch 39/500\n",
      "0s - loss: 119.5061 - r2_keras: 0.2566 - acc: 8.9100e-04 - val_loss: 71.2344 - val_r2_keras: 0.5512 - val_acc: 0.0000e+00\n",
      "Epoch 40/500\n",
      "0s - loss: 110.1887 - r2_keras: 0.3229 - acc: 5.9400e-04 - val_loss: 70.9657 - val_r2_keras: 0.5527 - val_acc: 0.0000e+00\n",
      "Epoch 41/500\n",
      "0s - loss: 107.9450 - r2_keras: 0.3420 - acc: 5.9400e-04 - val_loss: 71.8174 - val_r2_keras: 0.5465 - val_acc: 0.0000e+00\n",
      "Epoch 42/500\n",
      "0s - loss: 108.5832 - r2_keras: 0.3343 - acc: 0.0000e+00 - val_loss: 66.5196 - val_r2_keras: 0.5816 - val_acc: 0.0000e+00\n",
      "Epoch 43/500\n",
      "0s - loss: 110.0007 - r2_keras: 0.3225 - acc: 2.9700e-04 - val_loss: 77.1752 - val_r2_keras: 0.5111 - val_acc: 0.0000e+00\n",
      "Epoch 44/500\n",
      "0s - loss: 106.6119 - r2_keras: 0.3517 - acc: 2.9700e-04 - val_loss: 73.1611 - val_r2_keras: 0.5383 - val_acc: 0.0024\n",
      "Epoch 45/500\n",
      "0s - loss: 108.2007 - r2_keras: 0.3356 - acc: 2.9700e-04 - val_loss: 74.8358 - val_r2_keras: 0.5197 - val_acc: 0.0012\n",
      "Epoch 46/500\n",
      "0s - loss: 102.9394 - r2_keras: 0.3830 - acc: 8.9100e-04 - val_loss: 68.4425 - val_r2_keras: 0.5693 - val_acc: 0.0000e+00\n",
      "Epoch 47/500\n",
      "0s - loss: 103.0558 - r2_keras: 0.3713 - acc: 2.9700e-04 - val_loss: 75.2463 - val_r2_keras: 0.5128 - val_acc: 0.0000e+00\n",
      "Epoch 48/500\n",
      "0s - loss: 101.0257 - r2_keras: 0.3753 - acc: 8.9100e-04 - val_loss: 69.5775 - val_r2_keras: 0.5598 - val_acc: 0.0024\n",
      "Epoch 49/500\n",
      "0s - loss: 103.0536 - r2_keras: 0.3614 - acc: 2.9700e-04 - val_loss: 70.2756 - val_r2_keras: 0.5543 - val_acc: 0.0000e+00\n",
      "Epoch 50/500\n",
      "0s - loss: 105.3493 - r2_keras: 0.3558 - acc: 5.9400e-04 - val_loss: 71.6668 - val_r2_keras: 0.5483 - val_acc: 0.0012\n",
      "Epoch 51/500\n",
      "0s - loss: 101.2237 - r2_keras: 0.3792 - acc: 0.0012 - val_loss: 67.8982 - val_r2_keras: 0.5725 - val_acc: 0.0000e+00\n",
      "Epoch 52/500\n",
      "0s - loss: 101.1616 - r2_keras: 0.3785 - acc: 0.0012 - val_loss: 68.6197 - val_r2_keras: 0.5632 - val_acc: 0.0000e+00\n",
      "Epoch 53/500\n",
      "0s - loss: 102.6896 - r2_keras: 0.3805 - acc: 0.0000e+00 - val_loss: 67.3735 - val_r2_keras: 0.5736 - val_acc: 0.0000e+00\n",
      "Epoch 54/500\n",
      "0s - loss: 102.5691 - r2_keras: 0.3644 - acc: 8.9100e-04 - val_loss: 71.8589 - val_r2_keras: 0.5389 - val_acc: 0.0012\n",
      "Epoch 55/500\n",
      "0s - loss: 100.6671 - r2_keras: 0.3818 - acc: 2.9700e-04 - val_loss: 69.7209 - val_r2_keras: 0.5597 - val_acc: 0.0000e+00\n",
      "Epoch 56/500\n",
      "0s - loss: 102.7898 - r2_keras: 0.3719 - acc: 0.0012 - val_loss: 69.7897 - val_r2_keras: 0.5527 - val_acc: 0.0012\n",
      "Epoch 57/500\n",
      "0s - loss: 104.0848 - r2_keras: 0.3545 - acc: 5.9400e-04 - val_loss: 69.2708 - val_r2_keras: 0.5595 - val_acc: 0.0000e+00\n",
      "Epoch 58/500\n",
      "0s - loss: 100.5842 - r2_keras: 0.3850 - acc: 0.0000e+00 - val_loss: 68.4804 - val_r2_keras: 0.5676 - val_acc: 0.0012\n",
      "Epoch 59/500\n",
      "0s - loss: 98.3215 - r2_keras: 0.4102 - acc: 5.9400e-04 - val_loss: 68.8011 - val_r2_keras: 0.5611 - val_acc: 0.0000e+00\n",
      "Epoch 60/500\n",
      "0s - loss: 97.5588 - r2_keras: 0.4109 - acc: 0.0000e+00 - val_loss: 69.4984 - val_r2_keras: 0.5585 - val_acc: 0.0012\n",
      "Epoch 61/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s - loss: 99.8065 - r2_keras: 0.3818 - acc: 2.9700e-04 - val_loss: 79.3565 - val_r2_keras: 0.4855 - val_acc: 0.0000e+00\n",
      "Epoch 62/500\n",
      "0s - loss: 96.6427 - r2_keras: 0.4003 - acc: 0.0000e+00 - val_loss: 69.5705 - val_r2_keras: 0.5572 - val_acc: 0.0012\n",
      "Epoch 63/500\n",
      "0s - loss: 97.0034 - r2_keras: 0.4173 - acc: 0.0000e+00 - val_loss: 68.0324 - val_r2_keras: 0.5696 - val_acc: 0.0012\n",
      "Epoch 00062: early stopping\n",
      "Fold 2: Score 0.618874\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 1024)              1610752   \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 768)               787200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 768)               3072      \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 768)               590592    \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 768)               3072      \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 768)               590592    \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 768)               3072      \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 768)               590592    \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 768)               3072      \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 1)                 769       \n",
      "=================================================================\n",
      "Total params: 8,401,665\n",
      "Trainable params: 8,385,281\n",
      "Non-trainable params: 16,384\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 3367 samples, validate on 842 samples\n",
      "Epoch 1/500\n",
      "1s - loss: 9841.9755 - r2_keras: -6.6578e+01 - acc: 0.0000e+00 - val_loss: 9002.2210 - val_r2_keras: -6.0433e+01 - val_acc: 0.0000e+00\n",
      "Epoch 2/500\n",
      "0s - loss: 7683.9425 - r2_keras: -5.2212e+01 - acc: 0.0000e+00 - val_loss: 5096.5751 - val_r2_keras: -3.3562e+01 - val_acc: 0.0000e+00\n",
      "Epoch 3/500\n",
      "0s - loss: 5104.3227 - r2_keras: -3.4036e+01 - acc: 0.0000e+00 - val_loss: 4338.2210 - val_r2_keras: -2.8407e+01 - val_acc: 0.0000e+00\n",
      "Epoch 4/500\n",
      "0s - loss: 3185.0831 - r2_keras: -2.0495e+01 - acc: 0.0000e+00 - val_loss: 3128.7744 - val_r2_keras: -2.0325e+01 - val_acc: 0.0000e+00\n",
      "Epoch 5/500\n",
      "0s - loss: 2062.9131 - r2_keras: -1.3090e+01 - acc: 2.9700e-04 - val_loss: 1570.9480 - val_r2_keras: -9.5603e+00 - val_acc: 0.0000e+00\n",
      "Epoch 6/500\n",
      "0s - loss: 1477.5568 - r2_keras: -9.0493e+00 - acc: 5.9400e-04 - val_loss: 1313.3889 - val_r2_keras: -7.7872e+00 - val_acc: 0.0000e+00\n",
      "Epoch 7/500\n",
      "0s - loss: 1035.3197 - r2_keras: -6.0630e+00 - acc: 2.9700e-04 - val_loss: 498.3807 - val_r2_keras: -2.3135e+00 - val_acc: 0.0000e+00\n",
      "Epoch 8/500\n",
      "0s - loss: 907.9447 - r2_keras: -5.2153e+00 - acc: 2.9700e-04 - val_loss: 394.9475 - val_r2_keras: -1.6511e+00 - val_acc: 0.0000e+00\n",
      "Epoch 9/500\n",
      "0s - loss: 507.8030 - r2_keras: -2.3398e+00 - acc: 0.0015 - val_loss: 395.4203 - val_r2_keras: -1.6097e+00 - val_acc: 0.0000e+00\n",
      "Epoch 10/500\n",
      "0s - loss: 416.1455 - r2_keras: -1.7539e+00 - acc: 2.9700e-04 - val_loss: 297.3929 - val_r2_keras: -9.3336e-01 - val_acc: 0.0000e+00\n",
      "Epoch 11/500\n",
      "0s - loss: 329.5178 - r2_keras: -1.1377e+00 - acc: 8.9100e-04 - val_loss: 223.9203 - val_r2_keras: -4.4634e-01 - val_acc: 0.0012\n",
      "Epoch 12/500\n",
      "0s - loss: 296.0234 - r2_keras: -9.2969e-01 - acc: 2.9700e-04 - val_loss: 251.1214 - val_r2_keras: -6.3424e-01 - val_acc: 0.0000e+00\n",
      "Epoch 13/500\n",
      "0s - loss: 270.2639 - r2_keras: -7.2214e-01 - acc: 5.9400e-04 - val_loss: 192.7643 - val_r2_keras: -2.4378e-01 - val_acc: 0.0000e+00\n",
      "Epoch 14/500\n",
      "0s - loss: 231.5179 - r2_keras: -5.2213e-01 - acc: 2.9700e-04 - val_loss: 133.6137 - val_r2_keras: 0.1327 - val_acc: 0.0024\n",
      "Epoch 15/500\n",
      "0s - loss: 234.5026 - r2_keras: -4.7470e-01 - acc: 2.9700e-04 - val_loss: 247.5173 - val_r2_keras: -6.0065e-01 - val_acc: 0.0012\n",
      "Epoch 16/500\n",
      "0s - loss: 180.9335 - r2_keras: -1.6617e-01 - acc: 0.0000e+00 - val_loss: 141.2022 - val_r2_keras: 0.1142 - val_acc: 0.0000e+00\n",
      "Epoch 17/500\n",
      "0s - loss: 144.4919 - r2_keras: 0.0873 - acc: 2.9700e-04 - val_loss: 96.9257 - val_r2_keras: 0.3865 - val_acc: 0.0012\n",
      "Epoch 18/500\n",
      "0s - loss: 132.1083 - r2_keras: 0.1573 - acc: 5.9400e-04 - val_loss: 93.4812 - val_r2_keras: 0.4198 - val_acc: 0.0000e+00\n",
      "Epoch 19/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s - loss: 133.0065 - r2_keras: 0.1481 - acc: 2.9700e-04 - val_loss: 98.7594 - val_r2_keras: 0.3925 - val_acc: 0.0000e+00\n",
      "Epoch 20/500\n",
      "0s - loss: 127.5612 - r2_keras: 0.2095 - acc: 0.0000e+00 - val_loss: 87.9520 - val_r2_keras: 0.4521 - val_acc: 0.0024\n",
      "Epoch 21/500\n",
      "0s - loss: 133.6195 - r2_keras: 0.1411 - acc: 2.9700e-04 - val_loss: 104.6115 - val_r2_keras: 0.3551 - val_acc: 0.0000e+00\n",
      "Epoch 22/500\n",
      "0s - loss: 138.8291 - r2_keras: 0.1152 - acc: 2.9700e-04 - val_loss: 111.1553 - val_r2_keras: 0.2795 - val_acc: 0.0000e+00\n",
      "Epoch 23/500\n",
      "0s - loss: 125.6824 - r2_keras: 0.2156 - acc: 0.0000e+00 - val_loss: 82.2570 - val_r2_keras: 0.4895 - val_acc: 0.0000e+00\n",
      "Epoch 24/500\n",
      "0s - loss: 122.8640 - r2_keras: 0.2230 - acc: 5.9400e-04 - val_loss: 91.5435 - val_r2_keras: 0.4119 - val_acc: 0.0000e+00\n",
      "Epoch 25/500\n",
      "0s - loss: 118.3552 - r2_keras: 0.2575 - acc: 2.9700e-04 - val_loss: 83.4461 - val_r2_keras: 0.4747 - val_acc: 0.0000e+00\n",
      "Epoch 26/500\n",
      "0s - loss: 117.3707 - r2_keras: 0.2788 - acc: 0.0015 - val_loss: 80.2709 - val_r2_keras: 0.5013 - val_acc: 0.0000e+00\n",
      "Epoch 27/500\n",
      "0s - loss: 121.0218 - r2_keras: 0.2451 - acc: 0.0000e+00 - val_loss: 84.0848 - val_r2_keras: 0.4664 - val_acc: 0.0000e+00\n",
      "Epoch 28/500\n",
      "0s - loss: 127.4503 - r2_keras: 0.1974 - acc: 2.9700e-04 - val_loss: 83.0926 - val_r2_keras: 0.4807 - val_acc: 0.0000e+00\n",
      "Epoch 29/500\n",
      "0s - loss: 117.3503 - r2_keras: 0.2616 - acc: 5.9400e-04 - val_loss: 82.2582 - val_r2_keras: 0.4866 - val_acc: 0.0000e+00\n",
      "Epoch 30/500\n",
      "0s - loss: 113.8571 - r2_keras: 0.2849 - acc: 8.9100e-04 - val_loss: 82.3207 - val_r2_keras: 0.4841 - val_acc: 0.0000e+00\n",
      "Epoch 31/500\n",
      "0s - loss: 116.9476 - r2_keras: 0.2672 - acc: 2.9700e-04 - val_loss: 80.9736 - val_r2_keras: 0.4967 - val_acc: 0.0000e+00\n",
      "Epoch 32/500\n",
      "0s - loss: 113.7197 - r2_keras: 0.2848 - acc: 8.9100e-04 - val_loss: 80.5531 - val_r2_keras: 0.5052 - val_acc: 0.0024\n",
      "Epoch 33/500\n",
      "0s - loss: 109.1844 - r2_keras: 0.3223 - acc: 0.0000e+00 - val_loss: 83.8415 - val_r2_keras: 0.4864 - val_acc: 0.0000e+00\n",
      "Epoch 34/500\n",
      "0s - loss: 114.1729 - r2_keras: 0.2873 - acc: 5.9400e-04 - val_loss: 83.7464 - val_r2_keras: 0.4784 - val_acc: 0.0012\n",
      "Epoch 35/500\n",
      "0s - loss: 112.2639 - r2_keras: 0.2993 - acc: 0.0000e+00 - val_loss: 93.9305 - val_r2_keras: 0.3986 - val_acc: 0.0024\n",
      "Epoch 36/500\n",
      "0s - loss: 115.0431 - r2_keras: 0.2754 - acc: 5.9400e-04 - val_loss: 81.5913 - val_r2_keras: 0.4969 - val_acc: 0.0024\n",
      "Epoch 37/500\n",
      "0s - loss: 111.9547 - r2_keras: 0.3038 - acc: 5.9400e-04 - val_loss: 89.8466 - val_r2_keras: 0.4517 - val_acc: 0.0012\n",
      "Epoch 38/500\n",
      "0s - loss: 108.6960 - r2_keras: 0.3302 - acc: 5.9400e-04 - val_loss: 80.1200 - val_r2_keras: 0.5011 - val_acc: 0.0000e+00\n",
      "Epoch 39/500\n",
      "0s - loss: 108.1957 - r2_keras: 0.3225 - acc: 5.9400e-04 - val_loss: 82.8572 - val_r2_keras: 0.4955 - val_acc: 0.0000e+00\n",
      "Epoch 40/500\n",
      "0s - loss: 113.2736 - r2_keras: 0.3038 - acc: 0.0000e+00 - val_loss: 82.5564 - val_r2_keras: 0.4991 - val_acc: 0.0012\n",
      "Epoch 41/500\n",
      "0s - loss: 109.0025 - r2_keras: 0.3240 - acc: 2.9700e-04 - val_loss: 84.1464 - val_r2_keras: 0.4842 - val_acc: 0.0024\n",
      "Epoch 42/500\n",
      "0s - loss: 106.5158 - r2_keras: 0.3318 - acc: 2.9700e-04 - val_loss: 82.3967 - val_r2_keras: 0.5003 - val_acc: 0.0000e+00\n",
      "Epoch 43/500\n",
      "0s - loss: 97.1314 - r2_keras: 0.3823 - acc: 2.9700e-04 - val_loss: 78.3910 - val_r2_keras: 0.5122 - val_acc: 0.0012\n",
      "Epoch 44/500\n",
      "0s - loss: 105.7367 - r2_keras: 0.3362 - acc: 8.9100e-04 - val_loss: 79.2721 - val_r2_keras: 0.5134 - val_acc: 0.0000e+00\n",
      "Epoch 45/500\n",
      "0s - loss: 107.0932 - r2_keras: 0.3336 - acc: 0.0000e+00 - val_loss: 79.4108 - val_r2_keras: 0.5088 - val_acc: 0.0000e+00\n",
      "Epoch 46/500\n",
      "0s - loss: 99.5143 - r2_keras: 0.3761 - acc: 2.9700e-04 - val_loss: 78.1072 - val_r2_keras: 0.5243 - val_acc: 0.0000e+00\n",
      "Epoch 47/500\n",
      "0s - loss: 100.9236 - r2_keras: 0.3734 - acc: 0.0012 - val_loss: 83.9317 - val_r2_keras: 0.4712 - val_acc: 0.0000e+00\n",
      "Epoch 48/500\n",
      "0s - loss: 103.2516 - r2_keras: 0.3423 - acc: 5.9400e-04 - val_loss: 86.8092 - val_r2_keras: 0.4613 - val_acc: 0.0012\n",
      "Epoch 49/500\n",
      "0s - loss: 105.8267 - r2_keras: 0.3479 - acc: 0.0000e+00 - val_loss: 86.9609 - val_r2_keras: 0.4604 - val_acc: 0.0036\n",
      "Epoch 50/500\n",
      "0s - loss: 102.6521 - r2_keras: 0.3553 - acc: 2.9700e-04 - val_loss: 79.3912 - val_r2_keras: 0.5120 - val_acc: 0.0024\n",
      "Epoch 51/500\n",
      "0s - loss: 96.0328 - r2_keras: 0.4005 - acc: 0.0018 - val_loss: 80.8617 - val_r2_keras: 0.5011 - val_acc: 0.0012\n",
      "Epoch 52/500\n",
      "0s - loss: 102.4166 - r2_keras: 0.3605 - acc: 2.9700e-04 - val_loss: 82.4979 - val_r2_keras: 0.4919 - val_acc: 0.0000e+00\n",
      "Epoch 53/500\n",
      "0s - loss: 99.6108 - r2_keras: 0.3654 - acc: 0.0015 - val_loss: 89.6037 - val_r2_keras: 0.4386 - val_acc: 0.0000e+00\n",
      "Epoch 54/500\n",
      "0s - loss: 98.3928 - r2_keras: 0.3925 - acc: 5.9400e-04 - val_loss: 84.5415 - val_r2_keras: 0.4846 - val_acc: 0.0000e+00\n",
      "Epoch 55/500\n",
      "0s - loss: 102.7784 - r2_keras: 0.3611 - acc: 5.9400e-04 - val_loss: 80.3836 - val_r2_keras: 0.5082 - val_acc: 0.0024\n",
      "Epoch 56/500\n",
      "0s - loss: 97.4335 - r2_keras: 0.3992 - acc: 0.0015 - val_loss: 76.8067 - val_r2_keras: 0.5254 - val_acc: 0.0000e+00\n",
      "Epoch 57/500\n",
      "0s - loss: 100.0194 - r2_keras: 0.3777 - acc: 0.0000e+00 - val_loss: 84.6956 - val_r2_keras: 0.4785 - val_acc: 0.0012\n",
      "Epoch 58/500\n",
      "0s - loss: 101.0505 - r2_keras: 0.3587 - acc: 0.0015 - val_loss: 87.5493 - val_r2_keras: 0.4571 - val_acc: 0.0000e+00\n",
      "Epoch 59/500\n",
      "0s - loss: 98.4780 - r2_keras: 0.3920 - acc: 2.9700e-04 - val_loss: 82.2758 - val_r2_keras: 0.4908 - val_acc: 0.0000e+00\n",
      "Epoch 60/500\n",
      "0s - loss: 92.1545 - r2_keras: 0.4325 - acc: 0.0015 - val_loss: 86.6600 - val_r2_keras: 0.4727 - val_acc: 0.0000e+00\n",
      "Epoch 61/500\n",
      "0s - loss: 95.2697 - r2_keras: 0.4128 - acc: 5.9400e-04 - val_loss: 87.5052 - val_r2_keras: 0.4587 - val_acc: 0.0000e+00\n",
      "Epoch 62/500\n",
      "0s - loss: 97.9487 - r2_keras: 0.3867 - acc: 0.0000e+00 - val_loss: 95.8601 - val_r2_keras: 0.4012 - val_acc: 0.0000e+00\n",
      "Epoch 63/500\n",
      "0s - loss: 99.5508 - r2_keras: 0.3743 - acc: 2.9700e-04 - val_loss: 86.7005 - val_r2_keras: 0.4601 - val_acc: 0.0012\n",
      "Epoch 64/500\n",
      "0s - loss: 94.9554 - r2_keras: 0.3970 - acc: 5.9400e-04 - val_loss: 83.7655 - val_r2_keras: 0.4843 - val_acc: 0.0024\n",
      "Epoch 65/500\n",
      "0s - loss: 93.8745 - r2_keras: 0.4254 - acc: 5.9400e-04 - val_loss: 82.5985 - val_r2_keras: 0.4915 - val_acc: 0.0012\n",
      "Epoch 66/500\n",
      "0s - loss: 86.9013 - r2_keras: 0.4555 - acc: 5.9400e-04 - val_loss: 84.8308 - val_r2_keras: 0.4707 - val_acc: 0.0000e+00\n",
      "Epoch 67/500\n",
      "0s - loss: 91.0517 - r2_keras: 0.4275 - acc: 2.9700e-04 - val_loss: 85.7800 - val_r2_keras: 0.4683 - val_acc: 0.0000e+00\n",
      "Epoch 68/500\n",
      "0s - loss: 95.8361 - r2_keras: 0.3989 - acc: 2.9700e-04 - val_loss: 88.4224 - val_r2_keras: 0.4497 - val_acc: 0.0012\n",
      "Epoch 69/500\n",
      "0s - loss: 92.1995 - r2_keras: 0.4189 - acc: 5.9400e-04 - val_loss: 84.0804 - val_r2_keras: 0.4787 - val_acc: 0.0024\n",
      "Epoch 70/500\n",
      "0s - loss: 88.6664 - r2_keras: 0.4303 - acc: 0.0018 - val_loss: 84.6503 - val_r2_keras: 0.4782 - val_acc: 0.0012\n",
      "Epoch 71/500\n",
      "0s - loss: 88.5947 - r2_keras: 0.4338 - acc: 5.9400e-04 - val_loss: 82.9224 - val_r2_keras: 0.4826 - val_acc: 0.0012\n",
      "Epoch 72/500\n",
      "0s - loss: 96.2695 - r2_keras: 0.4098 - acc: 0.0000e+00 - val_loss: 91.1261 - val_r2_keras: 0.4246 - val_acc: 0.0000e+00\n",
      "Epoch 73/500\n",
      "0s - loss: 91.0792 - r2_keras: 0.4231 - acc: 0.0012 - val_loss: 89.8397 - val_r2_keras: 0.4448 - val_acc: 0.0000e+00\n",
      "Epoch 74/500\n",
      "0s - loss: 89.7083 - r2_keras: 0.4405 - acc: 2.9700e-04 - val_loss: 84.1898 - val_r2_keras: 0.4826 - val_acc: 0.0000e+00\n",
      "Epoch 75/500\n",
      "0s - loss: 84.0681 - r2_keras: 0.4623 - acc: 5.9400e-04 - val_loss: 87.5403 - val_r2_keras: 0.4612 - val_acc: 0.0012\n",
      "Epoch 76/500\n",
      "0s - loss: 83.1438 - r2_keras: 0.4735 - acc: 5.9400e-04 - val_loss: 99.2008 - val_r2_keras: 0.3688 - val_acc: 0.0024\n",
      "Epoch 77/500\n",
      "0s - loss: 90.1819 - r2_keras: 0.4329 - acc: 2.9700e-04 - val_loss: 83.2721 - val_r2_keras: 0.4851 - val_acc: 0.0012\n",
      "Epoch 00076: early stopping\n",
      "Fold 3: Score 0.557473\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_41 (Dense)             (None, 1024)              1610752   \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 768)               787200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 768)               3072      \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 768)               590592    \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 768)               3072      \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 768)               590592    \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 768)               3072      \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 768)               590592    \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 768)               3072      \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 1)                 769       \n",
      "=================================================================\n",
      "Total params: 8,401,665\n",
      "Trainable params: 8,385,281\n",
      "Non-trainable params: 16,384\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3368 samples, validate on 841 samples\n",
      "Epoch 1/500\n",
      "1s - loss: 9911.6602 - r2_keras: -6.5131e+01 - acc: 0.0000e+00 - val_loss: 8467.0732 - val_r2_keras: -6.4851e+01 - val_acc: 0.0000e+00\n",
      "Epoch 2/500\n",
      "0s - loss: 7694.0727 - r2_keras: -4.9522e+01 - acc: 0.0000e+00 - val_loss: 4748.9309 - val_r2_keras: -3.5961e+01 - val_acc: 0.0000e+00\n",
      "Epoch 3/500\n",
      "0s - loss: 5086.3709 - r2_keras: -3.2257e+01 - acc: 0.0000e+00 - val_loss: 3248.8483 - val_r2_keras: -2.4381e+01 - val_acc: 0.0000e+00\n",
      "Epoch 4/500\n",
      "0s - loss: 3222.6010 - r2_keras: -2.0518e+01 - acc: 0.0000e+00 - val_loss: 2249.6190 - val_r2_keras: -1.6600e+01 - val_acc: 0.0000e+00\n",
      "Epoch 5/500\n",
      "0s - loss: 2054.2886 - r2_keras: -1.2500e+01 - acc: 0.0000e+00 - val_loss: 1164.3658 - val_r2_keras: -8.0209e+00 - val_acc: 0.0000e+00\n",
      "Epoch 6/500\n",
      "0s - loss: 1274.7617 - r2_keras: -7.3594e+00 - acc: 2.9691e-04 - val_loss: 1026.7409 - val_r2_keras: -6.9689e+00 - val_acc: 0.0000e+00\n",
      "Epoch 7/500\n",
      "0s - loss: 847.5003 - r2_keras: -4.4695e+00 - acc: 5.9382e-04 - val_loss: 940.3844 - val_r2_keras: -6.3636e+00 - val_acc: 0.0000e+00\n",
      "Epoch 8/500\n",
      "0s - loss: 661.2078 - r2_keras: -3.2923e+00 - acc: 5.9382e-04 - val_loss: 328.8917 - val_r2_keras: -1.5744e+00 - val_acc: 0.0000e+00\n",
      "Epoch 9/500\n",
      "0s - loss: 473.2541 - r2_keras: -2.0518e+00 - acc: 2.9691e-04 - val_loss: 235.0559 - val_r2_keras: -8.3372e-01 - val_acc: 0.0000e+00\n",
      "Epoch 10/500\n",
      "0s - loss: 358.1177 - r2_keras: -1.2879e+00 - acc: 0.0000e+00 - val_loss: 202.4747 - val_r2_keras: -5.7727e-01 - val_acc: 0.0000e+00\n",
      "Epoch 11/500\n",
      "0s - loss: 279.1864 - r2_keras: -7.4057e-01 - acc: 5.9382e-04 - val_loss: 162.3573 - val_r2_keras: -2.6146e-01 - val_acc: 0.0000e+00\n",
      "Epoch 12/500\n",
      "0s - loss: 239.5638 - r2_keras: -5.6441e-01 - acc: 8.9074e-04 - val_loss: 130.9876 - val_r2_keras: -1.1015e-02 - val_acc: 0.0000e+00\n",
      "Epoch 13/500\n",
      "0s - loss: 267.0621 - r2_keras: -6.7984e-01 - acc: 0.0000e+00 - val_loss: 136.8813 - val_r2_keras: -5.9285e-02 - val_acc: 0.0000e+00\n",
      "Epoch 14/500\n",
      "0s - loss: 203.8635 - r2_keras: -2.6742e-01 - acc: 2.9691e-04 - val_loss: 99.8529 - val_r2_keras: 0.2318 - val_acc: 0.0000e+00\n",
      "Epoch 15/500\n",
      "0s - loss: 175.8243 - r2_keras: -7.2278e-02 - acc: 2.9691e-04 - val_loss: 93.7758 - val_r2_keras: 0.2790 - val_acc: 0.0012\n",
      "Epoch 16/500\n",
      "0s - loss: 171.6893 - r2_keras: -4.4166e-02 - acc: 5.9382e-04 - val_loss: 92.6000 - val_r2_keras: 0.2920 - val_acc: 0.0000e+00\n",
      "Epoch 17/500\n",
      "0s - loss: 186.5710 - r2_keras: -1.1757e-01 - acc: 5.9382e-04 - val_loss: 81.1838 - val_r2_keras: 0.3794 - val_acc: 0.0012\n",
      "Epoch 18/500\n",
      "0s - loss: 157.0585 - r2_keras: 0.0558 - acc: 8.9074e-04 - val_loss: 99.9247 - val_r2_keras: 0.2347 - val_acc: 0.0000e+00\n",
      "Epoch 19/500\n",
      "0s - loss: 156.4020 - r2_keras: 0.0471 - acc: 5.9382e-04 - val_loss: 68.2315 - val_r2_keras: 0.4803 - val_acc: 0.0000e+00\n",
      "Epoch 20/500\n",
      "0s - loss: 181.3267 - r2_keras: -1.3454e-01 - acc: 2.9691e-04 - val_loss: 86.5743 - val_r2_keras: 0.3382 - val_acc: 0.0012\n",
      "Epoch 21/500\n",
      "0s - loss: 151.6561 - r2_keras: 0.0684 - acc: 0.0000e+00 - val_loss: 64.2757 - val_r2_keras: 0.5089 - val_acc: 0.0000e+00\n",
      "Epoch 22/500\n",
      "0s - loss: 132.1321 - r2_keras: 0.2050 - acc: 5.9382e-04 - val_loss: 73.7627 - val_r2_keras: 0.4373 - val_acc: 0.0000e+00\n",
      "Epoch 23/500\n",
      "0s - loss: 134.8809 - r2_keras: 0.1713 - acc: 2.9691e-04 - val_loss: 66.0273 - val_r2_keras: 0.4967 - val_acc: 0.0000e+00\n",
      "Epoch 24/500\n",
      "0s - loss: 132.4605 - r2_keras: 0.2045 - acc: 2.9691e-04 - val_loss: 71.8168 - val_r2_keras: 0.4532 - val_acc: 0.0012\n",
      "Epoch 25/500\n",
      "0s - loss: 133.8064 - r2_keras: 0.1977 - acc: 2.9691e-04 - val_loss: 69.8717 - val_r2_keras: 0.4666 - val_acc: 0.0000e+00\n",
      "Epoch 26/500\n",
      "0s - loss: 126.0372 - r2_keras: 0.2386 - acc: 5.9382e-04 - val_loss: 66.2340 - val_r2_keras: 0.4954 - val_acc: 0.0000e+00\n",
      "Epoch 27/500\n",
      "0s - loss: 130.9518 - r2_keras: 0.2152 - acc: 5.9382e-04 - val_loss: 71.9601 - val_r2_keras: 0.4477 - val_acc: 0.0000e+00\n",
      "Epoch 28/500\n",
      "0s - loss: 161.9929 - r2_keras: -1.7378e-02 - acc: 8.9074e-04 - val_loss: 64.3857 - val_r2_keras: 0.5076 - val_acc: 0.0012\n",
      "Epoch 29/500\n",
      "0s - loss: 131.2445 - r2_keras: 0.2050 - acc: 0.0012 - val_loss: 64.9092 - val_r2_keras: 0.5047 - val_acc: 0.0000e+00\n",
      "Epoch 30/500\n",
      "2s - loss: 125.2298 - r2_keras: 0.2540 - acc: 2.9691e-04 - val_loss: 55.9256 - val_r2_keras: 0.5766 - val_acc: 0.0000e+00\n",
      "Epoch 31/500\n",
      "0s - loss: 125.0480 - r2_keras: 0.2558 - acc: 5.9382e-04 - val_loss: 63.1809 - val_r2_keras: 0.5194 - val_acc: 0.0000e+00\n",
      "Epoch 32/500\n",
      "0s - loss: 125.3291 - r2_keras: 0.2539 - acc: 5.9382e-04 - val_loss: 72.2841 - val_r2_keras: 0.4506 - val_acc: 0.0000e+00\n",
      "Epoch 33/500\n",
      "0s - loss: 133.7272 - r2_keras: 0.2009 - acc: 2.9691e-04 - val_loss: 81.2435 - val_r2_keras: 0.3806 - val_acc: 0.0000e+00\n",
      "Epoch 34/500\n",
      "0s - loss: 135.9892 - r2_keras: 0.1871 - acc: 8.9074e-04 - val_loss: 65.2830 - val_r2_keras: 0.5035 - val_acc: 0.0000e+00\n",
      "Epoch 35/500\n",
      "0s - loss: 122.8573 - r2_keras: 0.2561 - acc: 2.9691e-04 - val_loss: 74.6987 - val_r2_keras: 0.4335 - val_acc: 0.0000e+00\n",
      "Epoch 36/500\n",
      "0s - loss: 124.3577 - r2_keras: 0.2573 - acc: 0.0012 - val_loss: 68.7969 - val_r2_keras: 0.4748 - val_acc: 0.0000e+00\n",
      "Epoch 37/500\n",
      "0s - loss: 128.5477 - r2_keras: 0.2205 - acc: 2.9691e-04 - val_loss: 63.3497 - val_r2_keras: 0.5199 - val_acc: 0.0012\n",
      "Epoch 38/500\n",
      "0s - loss: 138.6858 - r2_keras: 0.1633 - acc: 0.0000e+00 - val_loss: 70.7876 - val_r2_keras: 0.4599 - val_acc: 0.0000e+00\n",
      "Epoch 39/500\n",
      "0s - loss: 124.5186 - r2_keras: 0.2486 - acc: 0.0000e+00 - val_loss: 62.3374 - val_r2_keras: 0.5271 - val_acc: 0.0000e+00\n",
      "Epoch 40/500\n",
      "0s - loss: 119.2555 - r2_keras: 0.2790 - acc: 8.9074e-04 - val_loss: 57.1130 - val_r2_keras: 0.5679 - val_acc: 0.0000e+00\n",
      "Epoch 41/500\n",
      "1s - loss: 114.8027 - r2_keras: 0.3113 - acc: 0.0012 - val_loss: 53.7425 - val_r2_keras: 0.5939 - val_acc: 0.0012\n",
      "Epoch 42/500\n",
      "0s - loss: 111.1033 - r2_keras: 0.3370 - acc: 0.0000e+00 - val_loss: 62.9695 - val_r2_keras: 0.5237 - val_acc: 0.0000e+00\n",
      "Epoch 43/500\n",
      "0s - loss: 115.9770 - r2_keras: 0.3089 - acc: 2.9691e-04 - val_loss: 59.9745 - val_r2_keras: 0.5450 - val_acc: 0.0000e+00\n",
      "Epoch 44/500\n",
      "1s - loss: 118.8705 - r2_keras: 0.2768 - acc: 5.9382e-04 - val_loss: 53.4142 - val_r2_keras: 0.5964 - val_acc: 0.0000e+00\n",
      "Epoch 45/500\n",
      "0s - loss: 113.1248 - r2_keras: 0.3255 - acc: 8.9074e-04 - val_loss: 60.9409 - val_r2_keras: 0.5394 - val_acc: 0.0012\n",
      "Epoch 46/500\n",
      "0s - loss: 109.5967 - r2_keras: 0.3461 - acc: 2.9691e-04 - val_loss: 67.8165 - val_r2_keras: 0.4829 - val_acc: 0.0000e+00\n",
      "Epoch 47/500\n",
      "0s - loss: 118.5798 - r2_keras: 0.2962 - acc: 5.9382e-04 - val_loss: 55.1993 - val_r2_keras: 0.5823 - val_acc: 0.0000e+00\n",
      "Epoch 48/500\n",
      "0s - loss: 113.2042 - r2_keras: 0.3268 - acc: 5.9382e-04 - val_loss: 63.0290 - val_r2_keras: 0.5230 - val_acc: 0.0000e+00\n",
      "Epoch 49/500\n",
      "0s - loss: 112.6088 - r2_keras: 0.3276 - acc: 8.9074e-04 - val_loss: 56.0265 - val_r2_keras: 0.5756 - val_acc: 0.0000e+00\n",
      "Epoch 50/500\n",
      "0s - loss: 109.9970 - r2_keras: 0.3434 - acc: 0.0000e+00 - val_loss: 55.5266 - val_r2_keras: 0.5785 - val_acc: 0.0000e+00\n",
      "Epoch 51/500\n",
      "0s - loss: 114.3927 - r2_keras: 0.3191 - acc: 0.0012 - val_loss: 60.0648 - val_r2_keras: 0.5447 - val_acc: 0.0000e+00\n",
      "Epoch 52/500\n",
      "1s - loss: 113.4343 - r2_keras: 0.3137 - acc: 5.9382e-04 - val_loss: 49.4760 - val_r2_keras: 0.6257 - val_acc: 0.0000e+00\n",
      "Epoch 53/500\n",
      "0s - loss: 111.1499 - r2_keras: 0.3406 - acc: 5.9382e-04 - val_loss: 53.4120 - val_r2_keras: 0.5976 - val_acc: 0.0000e+00\n",
      "Epoch 54/500\n",
      "0s - loss: 109.4684 - r2_keras: 0.3357 - acc: 2.9691e-04 - val_loss: 56.3748 - val_r2_keras: 0.5734 - val_acc: 0.0000e+00\n",
      "Epoch 55/500\n",
      "0s - loss: 109.3087 - r2_keras: 0.3577 - acc: 5.9382e-04 - val_loss: 55.6526 - val_r2_keras: 0.5790 - val_acc: 0.0000e+00\n",
      "Epoch 56/500\n",
      "0s - loss: 108.9046 - r2_keras: 0.3524 - acc: 2.9691e-04 - val_loss: 54.1201 - val_r2_keras: 0.5903 - val_acc: 0.0000e+00\n",
      "Epoch 57/500\n",
      "0s - loss: 110.6977 - r2_keras: 0.3369 - acc: 8.9074e-04 - val_loss: 53.3865 - val_r2_keras: 0.5962 - val_acc: 0.0000e+00\n",
      "Epoch 58/500\n",
      "0s - loss: 111.4435 - r2_keras: 0.3326 - acc: 0.0018 - val_loss: 55.1573 - val_r2_keras: 0.5830 - val_acc: 0.0000e+00\n",
      "Epoch 59/500\n",
      "0s - loss: 107.7092 - r2_keras: 0.3619 - acc: 5.9382e-04 - val_loss: 51.6762 - val_r2_keras: 0.6105 - val_acc: 0.0012\n",
      "Epoch 60/500\n",
      "0s - loss: 110.5624 - r2_keras: 0.3343 - acc: 8.9074e-04 - val_loss: 56.8251 - val_r2_keras: 0.5695 - val_acc: 0.0000e+00\n",
      "Epoch 61/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s - loss: 109.5098 - r2_keras: 0.3395 - acc: 2.9691e-04 - val_loss: 53.0051 - val_r2_keras: 0.5984 - val_acc: 0.0000e+00\n",
      "Epoch 62/500\n",
      "0s - loss: 106.3331 - r2_keras: 0.3665 - acc: 0.0015 - val_loss: 60.4082 - val_r2_keras: 0.5424 - val_acc: 0.0000e+00\n",
      "Epoch 63/500\n",
      "0s - loss: 107.9065 - r2_keras: 0.3533 - acc: 0.0015 - val_loss: 67.1877 - val_r2_keras: 0.4906 - val_acc: 0.0000e+00\n",
      "Epoch 64/500\n",
      "0s - loss: 109.5214 - r2_keras: 0.3538 - acc: 0.0015 - val_loss: 57.3662 - val_r2_keras: 0.5663 - val_acc: 0.0000e+00\n",
      "Epoch 65/500\n",
      "0s - loss: 102.8165 - r2_keras: 0.3759 - acc: 0.0000e+00 - val_loss: 60.0273 - val_r2_keras: 0.5470 - val_acc: 0.0000e+00\n",
      "Epoch 66/500\n",
      "0s - loss: 106.4984 - r2_keras: 0.3630 - acc: 0.0015 - val_loss: 57.7389 - val_r2_keras: 0.5631 - val_acc: 0.0000e+00\n",
      "Epoch 67/500\n",
      "0s - loss: 101.6404 - r2_keras: 0.3972 - acc: 8.9074e-04 - val_loss: 60.9484 - val_r2_keras: 0.5391 - val_acc: 0.0000e+00\n",
      "Epoch 68/500\n",
      "0s - loss: 103.4919 - r2_keras: 0.3858 - acc: 5.9382e-04 - val_loss: 61.8443 - val_r2_keras: 0.5319 - val_acc: 0.0000e+00\n",
      "Epoch 69/500\n",
      "0s - loss: 106.1026 - r2_keras: 0.3764 - acc: 8.9074e-04 - val_loss: 57.5480 - val_r2_keras: 0.5642 - val_acc: 0.0000e+00\n",
      "Epoch 70/500\n",
      "0s - loss: 105.8820 - r2_keras: 0.3686 - acc: 5.9382e-04 - val_loss: 55.9376 - val_r2_keras: 0.5770 - val_acc: 0.0000e+00\n",
      "Epoch 71/500\n",
      "0s - loss: 105.6329 - r2_keras: 0.3728 - acc: 8.9074e-04 - val_loss: 53.8226 - val_r2_keras: 0.5939 - val_acc: 0.0000e+00\n",
      "Epoch 72/500\n",
      "0s - loss: 101.9477 - r2_keras: 0.3939 - acc: 8.9074e-04 - val_loss: 62.5729 - val_r2_keras: 0.5250 - val_acc: 0.0000e+00\n",
      "Epoch 73/500\n",
      "0s - loss: 105.6775 - r2_keras: 0.3826 - acc: 8.9074e-04 - val_loss: 51.8944 - val_r2_keras: 0.6083 - val_acc: 0.0000e+00\n",
      "Epoch 00072: early stopping\n",
      "Fold 4: Score 0.625231\n",
      "=====================\n",
      "Final Score 0.573844\n",
      "=====================\n"
     ]
    }
   ],
   "source": [
    "#K-FOLD\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits = n_splits)\n",
    "kf.get_n_splits(X_train_all)\n",
    "\n",
    "predictions = np.zeros((X_train_all.shape[0], n_splits))\n",
    "score = 0\n",
    "\n",
    "for fold, (ind_train, ind_valid) in enumerate(kf.split(X_train_all)):\n",
    "\n",
    "    X_train, X_valid = X_train_all[ind_train, :], X_train_all[ind_valid, :]\n",
    "    y_train, y_valid = y_train_all[ind_train], y_train_all[ind_valid]\n",
    "\n",
    "    # fit estimator\n",
    "    history = estimator.fit(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        batch_size = 64,\n",
    "        epochs = 500,\n",
    "        validation_data = (X_valid, y_valid),\n",
    "        verbose = 2,\n",
    "        callbacks = callbacks,\n",
    "        shuffle = True\n",
    "    )\n",
    "    \n",
    "    if os.path.isfile(model_path):\n",
    "        history.model.load_weights(model_path)\n",
    "    \n",
    "    pred = history.model.predict(X_valid)\n",
    "    \n",
    "    score_fold = r2_score(y_valid, pred)\n",
    "    score += score_fold\n",
    "\n",
    "    print('Fold %d: Score %f'%(fold, score_fold))\n",
    "\n",
    "\n",
    "score /= n_splits\n",
    "\n",
    "print('=====================')\n",
    "\n",
    "print( 'Final Score %f'%score)\n",
    "\n",
    "print('=====================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
