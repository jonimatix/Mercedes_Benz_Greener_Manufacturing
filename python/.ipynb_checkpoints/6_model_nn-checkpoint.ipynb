{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Keras is a deep learning library that wraps the efficient numerical libraries Theano and TensorFlow.\n",
    "# It provides a clean and simple API that allows you to define and evaluate deep learning models in just a few lines of code.from keras.models import Sequential, load_model\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# define custom R2 metrics for Keras backend\n",
    "from keras import backend as K\n",
    "# to tune the NN\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.regularizers import l2\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define path to save model\n",
    "import os\n",
    "model_path = \"../../data/Mercedes_Benz_Greener_Manufacturing/model/model_nn.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data\n",
    "dt_model = pd.read_csv(\"../../data/Mercedes_Benz_Greener_Manufacturing/data/dt_all_preprocess.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove ohe\n",
    "dt_model = dt_model.drop(dt_model.filter(regex = \"Encode_ohe\").columns, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# r_2 for nn\n",
    "def r2_keras(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square( y_true - y_pred )) \n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) ) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X, y, ID\n",
    "X_train_all = dt_model.loc[dt_model[\"IsTrainTest\"] == \"train\"].drop([\"ID\", \"y\", \"IsTrainTest\"], axis = 1).as_matrix()\n",
    "X_test = dt_model.loc[dt_model[\"IsTrainTest\"] == \"test\"].drop([\"ID\", \"y\", \"IsTrainTest\"], axis = 1).as_matrix()\n",
    "y_train_all = dt_model.loc[dt_model[\"IsTrainTest\"] == \"train\"].y.values\n",
    "y_test = dt_model.loc[dt_model[\"IsTrainTest\"] == \"test\"].y.values\n",
    "ID_train_all = dt_model.loc[dt_model[\"IsTrainTest\"] == \"train\"].ID.values\n",
    "ID_test = dt_model.loc[dt_model[\"IsTrainTest\"] == \"test\"].ID.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras\n",
    "def model(dropout_level = 0.25, activation = 'tanh'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1024, input_dim=input_dims, kernel_initializer=\"he_normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dropout(dropout_level))\n",
    "    \n",
    "    model.add(Dense(1024, kernel_initializer=\"he_normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dropout(dropout_level))\n",
    "    \n",
    "    model.add(Dense(1024, kernel_initializer=\"he_normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dropout(dropout_level))\n",
    "    \n",
    "    model.add(Dense(1024, kernel_initializer=\"he_normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dropout(dropout_level))\n",
    "    \n",
    "    model.add(Dense(1024, kernel_initializer=\"he_normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dropout(dropout_level))\n",
    "    \n",
    "    model.add(Dense(768, kernel_initializer=\"he_normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dropout(dropout_level))\n",
    "    \n",
    "    model.add(Dense(768, kernel_initializer=\"he_normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dropout(dropout_level))\n",
    "    \n",
    "    model.add(Dense(768, kernel_initializer=\"he_normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dropout(dropout_level))\n",
    "\n",
    "    model.add(Dense(768, kernel_initializer=\"he_normal\", kernel_regularizer = l2(1.e-5)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dropout(dropout_level))\n",
    "    \n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "    model.compile(loss = \"mean_squared_error\", # one may use 'mean_absolute_error' as alternative\n",
    "                  optimizer = \"adam\",\n",
    "                  metrics = [r2_keras, \"accuracy\"] # you can add several if needed\n",
    "                 )\n",
    "    \n",
    "    # Visualize NN architecture\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dims = X_train_all.shape[1]\n",
    "estimator = KerasRegressor(\n",
    "    build_fn = model, \n",
    "    nb_epoch = 300, \n",
    "    batch_size = 35,\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor = 'val_loss', \n",
    "        patience = 20,\n",
    "        verbose = 1),\n",
    "    ModelCheckpoint(\n",
    "        model_path, \n",
    "        monitor = 'val_loss', \n",
    "        save_best_only = True, \n",
    "        verbose = 0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1024)              1394688   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 768)               787200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 768)               3072      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 768)               590592    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 768)               3072      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 768)               590592    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 768)               3072      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 768)               590592    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 768)               3072      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 769       \n",
      "=================================================================\n",
      "Total params: 8,185,601\n",
      "Trainable params: 8,169,217\n",
      "Non-trainable params: 16,384\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 3367 samples, validate on 842 samples\n",
      "Epoch 1/500\n",
      "3s - loss: 9758.0297 - r2_keras: -6.3591e+01 - acc: 0.0000e+00 - val_loss: 9211.3939 - val_r2_keras: -6.5090e+01 - val_acc: 0.0000e+00\n",
      "Epoch 2/500\n",
      "3s - loss: 7298.8720 - r2_keras: -4.8271e+01 - acc: 0.0000e+00 - val_loss: 3989.7031 - val_r2_keras: -2.7043e+01 - val_acc: 0.0000e+00\n",
      "Epoch 3/500\n",
      "3s - loss: 4756.9463 - r2_keras: -3.1438e+01 - acc: 0.0000e+00 - val_loss: 2226.3664 - val_r2_keras: -1.4362e+01 - val_acc: 0.0000e+00\n",
      "Epoch 4/500\n",
      "3s - loss: 3022.1046 - r2_keras: -1.9479e+01 - acc: 0.0000e+00 - val_loss: 1803.7728 - val_r2_keras: -1.1536e+01 - val_acc: 0.0000e+00\n",
      "Epoch 5/500\n",
      "2s - loss: 1955.4603 - r2_keras: -1.2171e+01 - acc: 2.9700e-04 - val_loss: 912.6339 - val_r2_keras: -5.2885e+00 - val_acc: 0.0000e+00\n",
      "Epoch 6/500\n",
      "2s - loss: 1139.6581 - r2_keras: -6.7755e+00 - acc: 2.9700e-04 - val_loss: 364.8433 - val_r2_keras: -1.4245e+00 - val_acc: 0.0000e+00\n",
      "Epoch 7/500\n",
      "2s - loss: 1099.6143 - r2_keras: -6.4401e+00 - acc: 2.9700e-04 - val_loss: 571.9090 - val_r2_keras: -2.9133e+00 - val_acc: 0.0000e+00\n",
      "Epoch 8/500\n",
      "3s - loss: 581.8135 - r2_keras: -2.9075e+00 - acc: 2.9700e-04 - val_loss: 335.9757 - val_r2_keras: -1.2382e+00 - val_acc: 0.0000e+00\n",
      "Epoch 9/500\n",
      "2s - loss: 372.2804 - r2_keras: -1.4204e+00 - acc: 0.0000e+00 - val_loss: 229.4470 - val_r2_keras: -5.1709e-01 - val_acc: 0.0000e+00\n",
      "Epoch 10/500\n",
      "3s - loss: 256.6717 - r2_keras: -6.5320e-01 - acc: 5.9400e-04 - val_loss: 165.3544 - val_r2_keras: -6.4651e-02 - val_acc: 0.0000e+00\n",
      "Epoch 11/500\n",
      "2s - loss: 194.5213 - r2_keras: -2.1901e-01 - acc: 2.9700e-04 - val_loss: 115.8300 - val_r2_keras: 0.2609 - val_acc: 0.0000e+00\n",
      "Epoch 12/500\n",
      "2s - loss: 168.7928 - r2_keras: -5.4206e-02 - acc: 5.9400e-04 - val_loss: 105.5510 - val_r2_keras: 0.3147 - val_acc: 0.0000e+00\n",
      "Epoch 13/500\n",
      "2s - loss: 150.1393 - r2_keras: 0.0506 - acc: 0.0000e+00 - val_loss: 103.6104 - val_r2_keras: 0.3236 - val_acc: 0.0012\n",
      "Epoch 14/500\n",
      "2s - loss: 151.3900 - r2_keras: 0.0176 - acc: 0.0012 - val_loss: 88.8673 - val_r2_keras: 0.4307 - val_acc: 0.0024\n",
      "Epoch 15/500\n",
      "3s - loss: 147.7472 - r2_keras: 0.0716 - acc: 8.9100e-04 - val_loss: 92.3666 - val_r2_keras: 0.3966 - val_acc: 0.0000e+00\n",
      "Epoch 16/500\n",
      "2s - loss: 143.7303 - r2_keras: 0.1015 - acc: 0.0000e+00 - val_loss: 79.1194 - val_r2_keras: 0.4870 - val_acc: 0.0000e+00\n",
      "Epoch 17/500\n",
      "3s - loss: 132.8453 - r2_keras: 0.1726 - acc: 5.9400e-04 - val_loss: 72.8088 - val_r2_keras: 0.5325 - val_acc: 0.0000e+00\n",
      "Epoch 18/500\n",
      "2s - loss: 135.4513 - r2_keras: 0.1803 - acc: 0.0000e+00 - val_loss: 79.7044 - val_r2_keras: 0.4856 - val_acc: 0.0000e+00\n",
      "Epoch 19/500\n",
      "3s - loss: 129.4478 - r2_keras: 0.1890 - acc: 5.9400e-04 - val_loss: 81.0921 - val_r2_keras: 0.4776 - val_acc: 0.0000e+00\n",
      "Epoch 20/500\n",
      "2s - loss: 131.0495 - r2_keras: 0.1789 - acc: 0.0000e+00 - val_loss: 83.7552 - val_r2_keras: 0.4647 - val_acc: 0.0000e+00\n",
      "Epoch 21/500\n",
      "2s - loss: 139.7965 - r2_keras: 0.1234 - acc: 0.0018 - val_loss: 94.0715 - val_r2_keras: 0.3890 - val_acc: 0.0000e+00\n",
      "Epoch 22/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2s - loss: 136.6703 - r2_keras: 0.1447 - acc: 2.9700e-04 - val_loss: 77.6855 - val_r2_keras: 0.4975 - val_acc: 0.0000e+00\n",
      "Epoch 23/500\n",
      "2s - loss: 114.6457 - r2_keras: 0.2843 - acc: 8.9100e-04 - val_loss: 79.6507 - val_r2_keras: 0.4944 - val_acc: 0.0000e+00\n",
      "Epoch 24/500\n",
      "1s - loss: 112.9420 - r2_keras: 0.3063 - acc: 8.9100e-04 - val_loss: 79.0859 - val_r2_keras: 0.4909 - val_acc: 0.0000e+00\n",
      "Epoch 25/500\n",
      "1s - loss: 117.1370 - r2_keras: 0.2839 - acc: 5.9400e-04 - val_loss: 80.5651 - val_r2_keras: 0.4866 - val_acc: 0.0012\n",
      "Epoch 26/500\n",
      "2s - loss: 125.1020 - r2_keras: 0.2209 - acc: 0.0012 - val_loss: 71.0640 - val_r2_keras: 0.5425 - val_acc: 0.0000e+00\n",
      "Epoch 27/500\n",
      "1s - loss: 125.0008 - r2_keras: 0.2153 - acc: 5.9400e-04 - val_loss: 74.3640 - val_r2_keras: 0.5333 - val_acc: 0.0024\n",
      "Epoch 28/500\n",
      "1s - loss: 115.3107 - r2_keras: 0.2877 - acc: 2.9700e-04 - val_loss: 77.8244 - val_r2_keras: 0.5004 - val_acc: 0.0000e+00\n",
      "Epoch 29/500\n",
      "2s - loss: 121.4988 - r2_keras: 0.2625 - acc: 5.9400e-04 - val_loss: 75.9165 - val_r2_keras: 0.5180 - val_acc: 0.0012\n",
      "Epoch 30/500\n",
      "2s - loss: 119.0164 - r2_keras: 0.2727 - acc: 5.9400e-04 - val_loss: 75.2924 - val_r2_keras: 0.5204 - val_acc: 0.0012\n",
      "Epoch 31/500\n",
      "2s - loss: 115.0747 - r2_keras: 0.2925 - acc: 2.9700e-04 - val_loss: 75.3221 - val_r2_keras: 0.5153 - val_acc: 0.0012\n",
      "Epoch 32/500\n",
      "2s - loss: 113.3153 - r2_keras: 0.3026 - acc: 0.0000e+00 - val_loss: 74.6019 - val_r2_keras: 0.5192 - val_acc: 0.0000e+00\n",
      "Epoch 33/500\n",
      "2s - loss: 109.6302 - r2_keras: 0.3280 - acc: 8.9100e-04 - val_loss: 79.7394 - val_r2_keras: 0.4875 - val_acc: 0.0000e+00\n",
      "Epoch 34/500\n",
      "1s - loss: 109.5558 - r2_keras: 0.3255 - acc: 2.9700e-04 - val_loss: 85.0625 - val_r2_keras: 0.4397 - val_acc: 0.0000e+00\n",
      "Epoch 35/500\n",
      "2s - loss: 111.5660 - r2_keras: 0.3089 - acc: 5.9400e-04 - val_loss: 74.7155 - val_r2_keras: 0.5168 - val_acc: 0.0000e+00\n",
      "Epoch 36/500\n",
      "2s - loss: 114.2049 - r2_keras: 0.3062 - acc: 2.9700e-04 - val_loss: 81.2346 - val_r2_keras: 0.4721 - val_acc: 0.0000e+00\n",
      "Epoch 37/500\n",
      "2s - loss: 110.7790 - r2_keras: 0.3065 - acc: 5.9400e-04 - val_loss: 76.9699 - val_r2_keras: 0.5130 - val_acc: 0.0036\n",
      "Epoch 38/500\n",
      "2s - loss: 106.9013 - r2_keras: 0.3462 - acc: 5.9400e-04 - val_loss: 74.3596 - val_r2_keras: 0.5151 - val_acc: 0.0012\n",
      "Epoch 39/500\n",
      "1s - loss: 132.8192 - r2_keras: 0.1740 - acc: 2.9700e-04 - val_loss: 70.3911 - val_r2_keras: 0.5549 - val_acc: 0.0012\n",
      "Epoch 40/500\n",
      "0s - loss: 120.6598 - r2_keras: 0.2372 - acc: 2.9700e-04 - val_loss: 78.1929 - val_r2_keras: 0.4808 - val_acc: 0.0012\n",
      "Epoch 41/500\n",
      "0s - loss: 122.9350 - r2_keras: 0.2335 - acc: 5.9400e-04 - val_loss: 80.4068 - val_r2_keras: 0.4804 - val_acc: 0.0012\n",
      "Epoch 42/500\n",
      "0s - loss: 112.4397 - r2_keras: 0.2925 - acc: 8.9100e-04 - val_loss: 70.9093 - val_r2_keras: 0.5411 - val_acc: 0.0036\n",
      "Epoch 43/500\n",
      "0s - loss: 132.6468 - r2_keras: 0.1713 - acc: 0.0000e+00 - val_loss: 79.9584 - val_r2_keras: 0.4779 - val_acc: 0.0000e+00\n",
      "Epoch 44/500\n",
      "1s - loss: 117.1335 - r2_keras: 0.2724 - acc: 8.9100e-04 - val_loss: 68.7204 - val_r2_keras: 0.5634 - val_acc: 0.0024\n",
      "Epoch 45/500\n",
      "0s - loss: 118.4797 - r2_keras: 0.2513 - acc: 2.9700e-04 - val_loss: 73.3711 - val_r2_keras: 0.5291 - val_acc: 0.0000e+00\n",
      "Epoch 46/500\n",
      "0s - loss: 115.8504 - r2_keras: 0.2855 - acc: 2.9700e-04 - val_loss: 69.1662 - val_r2_keras: 0.5516 - val_acc: 0.0012\n",
      "Epoch 47/500\n",
      "0s - loss: 105.5166 - r2_keras: 0.3423 - acc: 2.9700e-04 - val_loss: 71.1684 - val_r2_keras: 0.5437 - val_acc: 0.0012\n",
      "Epoch 48/500\n",
      "0s - loss: 109.7649 - r2_keras: 0.3170 - acc: 5.9400e-04 - val_loss: 72.2054 - val_r2_keras: 0.5378 - val_acc: 0.0012\n",
      "Epoch 49/500\n",
      "0s - loss: 107.3689 - r2_keras: 0.3246 - acc: 2.9700e-04 - val_loss: 70.6731 - val_r2_keras: 0.5368 - val_acc: 0.0000e+00\n",
      "Epoch 50/500\n",
      "0s - loss: 105.5108 - r2_keras: 0.3540 - acc: 2.9700e-04 - val_loss: 73.2731 - val_r2_keras: 0.5212 - val_acc: 0.0000e+00\n",
      "Epoch 51/500\n",
      "0s - loss: 107.5763 - r2_keras: 0.3649 - acc: 5.9400e-04 - val_loss: 71.3667 - val_r2_keras: 0.5427 - val_acc: 0.0012\n",
      "Epoch 52/500\n",
      "0s - loss: 108.7579 - r2_keras: 0.3233 - acc: 5.9400e-04 - val_loss: 72.1200 - val_r2_keras: 0.5341 - val_acc: 0.0012\n",
      "Epoch 53/500\n",
      "0s - loss: 107.2694 - r2_keras: 0.3316 - acc: 0.0012 - val_loss: 69.4030 - val_r2_keras: 0.5651 - val_acc: 0.0000e+00\n",
      "Epoch 54/500\n",
      "0s - loss: 128.1329 - r2_keras: 0.1968 - acc: 2.9700e-04 - val_loss: 81.6590 - val_r2_keras: 0.4793 - val_acc: 0.0024\n",
      "Epoch 55/500\n",
      "0s - loss: 104.8208 - r2_keras: 0.3572 - acc: 0.0000e+00 - val_loss: 69.7148 - val_r2_keras: 0.5559 - val_acc: 0.0012\n",
      "Epoch 56/500\n",
      "1s - loss: 107.3610 - r2_keras: 0.3398 - acc: 5.9400e-04 - val_loss: 66.8146 - val_r2_keras: 0.5717 - val_acc: 0.0000e+00\n",
      "Epoch 57/500\n",
      "1s - loss: 104.8046 - r2_keras: 0.3474 - acc: 5.9400e-04 - val_loss: 66.1856 - val_r2_keras: 0.5791 - val_acc: 0.0012\n",
      "Epoch 58/500\n",
      "1s - loss: 100.6722 - r2_keras: 0.3721 - acc: 2.9700e-04 - val_loss: 65.5714 - val_r2_keras: 0.5791 - val_acc: 0.0012\n",
      "Epoch 59/500\n",
      "0s - loss: 101.0619 - r2_keras: 0.3625 - acc: 2.9700e-04 - val_loss: 66.8934 - val_r2_keras: 0.5651 - val_acc: 0.0000e+00\n",
      "Epoch 60/500\n",
      "0s - loss: 108.3444 - r2_keras: 0.3274 - acc: 8.9100e-04 - val_loss: 80.0303 - val_r2_keras: 0.4834 - val_acc: 0.0000e+00\n",
      "Epoch 61/500\n",
      "0s - loss: 101.9838 - r2_keras: 0.3646 - acc: 2.9700e-04 - val_loss: 73.2137 - val_r2_keras: 0.5245 - val_acc: 0.0000e+00\n",
      "Epoch 62/500\n",
      "0s - loss: 100.6203 - r2_keras: 0.3680 - acc: 5.9400e-04 - val_loss: 69.0653 - val_r2_keras: 0.5593 - val_acc: 0.0012\n",
      "Epoch 63/500\n",
      "0s - loss: 100.5239 - r2_keras: 0.3753 - acc: 5.9400e-04 - val_loss: 71.6326 - val_r2_keras: 0.5398 - val_acc: 0.0000e+00\n",
      "Epoch 64/500\n",
      "0s - loss: 102.0802 - r2_keras: 0.3574 - acc: 5.9400e-04 - val_loss: 68.9814 - val_r2_keras: 0.5579 - val_acc: 0.0012\n",
      "Epoch 65/500\n",
      "0s - loss: 94.6906 - r2_keras: 0.4262 - acc: 0.0000e+00 - val_loss: 68.8467 - val_r2_keras: 0.5547 - val_acc: 0.0024\n",
      "Epoch 66/500\n",
      "0s - loss: 96.4419 - r2_keras: 0.4107 - acc: 2.9700e-04 - val_loss: 71.6912 - val_r2_keras: 0.5259 - val_acc: 0.0000e+00\n",
      "Epoch 67/500\n",
      "0s - loss: 101.1307 - r2_keras: 0.3726 - acc: 5.9400e-04 - val_loss: 68.9682 - val_r2_keras: 0.5600 - val_acc: 0.0024\n",
      "Epoch 68/500\n",
      "0s - loss: 100.5899 - r2_keras: 0.3789 - acc: 8.9100e-04 - val_loss: 69.0406 - val_r2_keras: 0.5545 - val_acc: 0.0000e+00\n",
      "Epoch 69/500\n",
      "0s - loss: 99.3129 - r2_keras: 0.3845 - acc: 2.9700e-04 - val_loss: 67.4645 - val_r2_keras: 0.5681 - val_acc: 0.0012\n",
      "Epoch 70/500\n",
      "0s - loss: 102.8178 - r2_keras: 0.3646 - acc: 0.0000e+00 - val_loss: 69.1512 - val_r2_keras: 0.5638 - val_acc: 0.0000e+00\n",
      "Epoch 71/500\n",
      "0s - loss: 97.1807 - r2_keras: 0.3915 - acc: 5.9400e-04 - val_loss: 77.4664 - val_r2_keras: 0.4992 - val_acc: 0.0000e+00\n",
      "Epoch 72/500\n",
      "0s - loss: 94.7345 - r2_keras: 0.4171 - acc: 2.9700e-04 - val_loss: 70.6365 - val_r2_keras: 0.5480 - val_acc: 0.0000e+00\n",
      "Epoch 73/500\n",
      "0s - loss: 95.0272 - r2_keras: 0.4145 - acc: 8.9100e-04 - val_loss: 70.5964 - val_r2_keras: 0.5525 - val_acc: 0.0024\n",
      "Epoch 74/500\n",
      "0s - loss: 95.4392 - r2_keras: 0.4043 - acc: 5.9400e-04 - val_loss: 73.4733 - val_r2_keras: 0.5141 - val_acc: 0.0012\n",
      "Epoch 75/500\n",
      "0s - loss: 96.2807 - r2_keras: 0.4093 - acc: 2.9700e-04 - val_loss: 72.2185 - val_r2_keras: 0.5295 - val_acc: 0.0012\n",
      "Epoch 76/500\n",
      "0s - loss: 97.6454 - r2_keras: 0.3860 - acc: 8.9100e-04 - val_loss: 75.1795 - val_r2_keras: 0.5070 - val_acc: 0.0012\n",
      "Epoch 77/500\n",
      "0s - loss: 90.5486 - r2_keras: 0.4440 - acc: 5.9400e-04 - val_loss: 73.2872 - val_r2_keras: 0.5294 - val_acc: 0.0012\n",
      "Epoch 78/500\n",
      "0s - loss: 91.4663 - r2_keras: 0.4364 - acc: 5.9400e-04 - val_loss: 75.5950 - val_r2_keras: 0.5214 - val_acc: 0.0000e+00\n",
      "Epoch 79/500\n",
      "0s - loss: 92.5776 - r2_keras: 0.4294 - acc: 2.9700e-04 - val_loss: 69.2351 - val_r2_keras: 0.5611 - val_acc: 0.0024\n",
      "Epoch 00078: early stopping\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'History' object has no attribute 'load_weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-6546d14798e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'History' object has no attribute 'load_weights'"
     ]
    }
   ],
   "source": [
    "#K-FOLD\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits = n_splits)\n",
    "kf.get_n_splits(X_train_all)\n",
    "\n",
    "predictions = np.zeros((X_train_all.shape[0], n_splits))\n",
    "score = 0\n",
    "\n",
    "for fold, (ind_train, ind_valid) in enumerate(kf.split(X_train_all)):\n",
    "\n",
    "    X_train, X_valid = X_train_all[ind_train, :], X_train_all[ind_valid, :]\n",
    "    y_train, y_valid = y_train_all[ind_train], y_train_all[ind_valid]\n",
    "\n",
    "    # fit estimator\n",
    "    history = estimator.fit(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        batch_size = 64,\n",
    "        epochs = 500,\n",
    "        validation_data = (X_valid, y_valid),\n",
    "        verbose = 2,\n",
    "        callbacks = callbacks,\n",
    "        shuffle = True\n",
    "    )\n",
    "    \n",
    "    if os.path.isfile(model_path):\n",
    "        history.model.load_weights(model_path)\n",
    "    \n",
    "    pred = history.model.predict(X_valid)\n",
    "    \n",
    "    score_fold = r2_score(y_valid, pred)\n",
    "    score += score_fold\n",
    "\n",
    "    print('Fold %d: Score %f'%(fold, score_fold))\n",
    "\n",
    "\n",
    "score /= n_splits\n",
    "\n",
    "print('=====================')\n",
    "\n",
    "print( 'Final Score %f'%score)\n",
    "\n",
    "print('=====================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_valid, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(pred, y_valid)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
