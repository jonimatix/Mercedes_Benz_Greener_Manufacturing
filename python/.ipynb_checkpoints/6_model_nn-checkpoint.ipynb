{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Keras is a deep learning library that wraps the efficient numerical libraries Theano and TensorFlow.\n",
    "# It provides a clean and simple API that allows you to define and evaluate deep learning models in just a few lines of code.from keras.models import Sequential, load_model\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# define custom R2 metrics for Keras backend\n",
    "from keras import backend as K\n",
    "# to tune the NN\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define path to save model\n",
    "import os\n",
    "model_path = \"../../data/Mercedes_Benz_Greener_Manufacturing/model/model_nn.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data\n",
    "dt_model = pd.read_csv(\"../../data/Mercedes_Benz_Greener_Manufacturing/data/dt_all_preprocess.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove ohe\n",
    "dt_model = dt_model.drop(dt_model.filter(regex = \"Encode_ohe\").columns, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# r_2 for nn\n",
    "def r2_keras(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square( y_true - y_pred )) \n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) ) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X, y, ID\n",
    "X_train_all = dt_model.loc[dt_model[\"IsTrainTest\"] == \"train\"].drop([\"ID\", \"y\", \"IsTrainTest\"], axis = 1).as_matrix()\n",
    "X_test = dt_model.loc[dt_model[\"IsTrainTest\"] == \"test\"].drop([\"ID\", \"y\", \"IsTrainTest\"], axis = 1).as_matrix()\n",
    "y_train_all = dt_model.loc[dt_model[\"IsTrainTest\"] == \"train\"].y.values\n",
    "y_test = dt_model.loc[dt_model[\"IsTrainTest\"] == \"test\"].y.values\n",
    "ID_train_all = dt_model.loc[dt_model[\"IsTrainTest\"] == \"train\"].ID.values\n",
    "ID_test = dt_model.loc[dt_model[\"IsTrainTest\"] == \"test\"].ID.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# keras\n",
    "def model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(input_dims * 2, input_dim = input_dims, activation = \"relu\"))\n",
    "    model.add(Dropout(.2))\n",
    "\n",
    "    model.add(Dense(input_dims, activation = \"relu\"))\n",
    "#     model.add(Dropout(.2))\n",
    "\n",
    "    model.add(Dense((input_dims * 2) // 2, activation = \"relu\"))\n",
    "    model.add(Dropout(.2))\n",
    "\n",
    "    model.add(Dense(input_dims, activation = \"relu\"))\n",
    "#     model.add(Dropout(.2))\n",
    "\n",
    "    model.add(Dense((input_dims*2)//2, activation = \"relu\"))\n",
    "    model.add(Dropout(.2))\n",
    "\n",
    "    model.add(Dense(input_dims, activation = \"relu\"))\n",
    "#     model.add(Dropout(.2))\n",
    "\n",
    "    model.add(Dense((input_dims*2)//2, activation = \"relu\"))\n",
    "    model.add(Dropout(.2))\n",
    "    \n",
    "    # Output Layer.\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(loss = \"mean_squared_error\", # one may use 'mean_absolute_error' as alternative\n",
    "                  optimizer = \"adam\",\n",
    "                  metrics = [r2_keras, \"accuracy\"] # you can add several if needed\n",
    "                 )\n",
    "    \n",
    "    # Visualize NN architecture\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dims = X_train_all.shape[1]\n",
    "estimator = KerasRegressor(\n",
    "    build_fn = model, \n",
    "    nb_epoch = 300, \n",
    "    batch_size = 35,\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor = 'val_loss', \n",
    "        patience = 20,\n",
    "        verbose = 1),\n",
    "    ModelCheckpoint(\n",
    "        model_path, \n",
    "        monitor = 'val_loss', \n",
    "        save_best_only = True, \n",
    "        verbose = 0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 2722)              3707364   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2722)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1361)              3706003   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1361)              1853682   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1361)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1361)              1853682   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1361)              1853682   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1361)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1361)              1853682   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1361)              1853682   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1361)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 1362      \n",
      "=================================================================\n",
      "Total params: 16,683,139\n",
      "Trainable params: 16,683,139\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 3367 samples, validate on 842 samples\n",
      "Epoch 1/500\n",
      "2s - loss: 1838.1034 - r2_keras: -1.2962e+01 - acc: 0.0000e+00 - val_loss: 74.4485 - val_r2_keras: 0.5109 - val_acc: 0.0024\n",
      "Epoch 2/500\n",
      "1s - loss: 151.6181 - r2_keras: 0.0054 - acc: 0.0000e+00 - val_loss: 115.0333 - val_r2_keras: 0.2261 - val_acc: 0.0000e+00\n",
      "Epoch 3/500\n",
      "1s - loss: 152.4101 - r2_keras: -5.0446e-03 - acc: 2.9700e-04 - val_loss: 128.7639 - val_r2_keras: 0.0638 - val_acc: 0.0000e+00\n",
      "Epoch 4/500\n",
      "1s - loss: 160.1599 - r2_keras: -4.2344e-02 - acc: 5.9400e-04 - val_loss: 169.7533 - val_r2_keras: -1.8280e-01 - val_acc: 0.0000e+00\n",
      "Epoch 5/500\n",
      "1s - loss: 137.5722 - r2_keras: 0.0957 - acc: 0.0000e+00 - val_loss: 86.6091 - val_r2_keras: 0.4404 - val_acc: 0.0012\n",
      "Epoch 6/500\n",
      "1s - loss: 135.6994 - r2_keras: 0.1047 - acc: 8.9100e-04 - val_loss: 240.4016 - val_r2_keras: -7.1201e-01 - val_acc: 0.0000e+00\n",
      "Epoch 7/500\n",
      "1s - loss: 152.1134 - r2_keras: 0.0022 - acc: 0.0000e+00 - val_loss: 76.2868 - val_r2_keras: 0.5122 - val_acc: 0.0048\n",
      "Epoch 8/500\n",
      "1s - loss: 122.3828 - r2_keras: 0.1988 - acc: 8.9100e-04 - val_loss: 189.2047 - val_r2_keras: -4.1121e-01 - val_acc: 0.0000e+00\n",
      "Epoch 9/500\n",
      "1s - loss: 141.8694 - r2_keras: 0.0692 - acc: 0.0000e+00 - val_loss: 105.5515 - val_r2_keras: 0.2481 - val_acc: 0.0000e+00\n",
      "Epoch 10/500\n",
      "1s - loss: 137.2165 - r2_keras: 0.1279 - acc: 0.0000e+00 - val_loss: 82.6479 - val_r2_keras: 0.4406 - val_acc: 0.0000e+00\n",
      "Epoch 11/500\n",
      "1s - loss: 176.2229 - r2_keras: -1.9448e-01 - acc: 5.9400e-04 - val_loss: 123.1826 - val_r2_keras: 0.1206 - val_acc: 0.0000e+00\n",
      "Epoch 12/500\n",
      "1s - loss: 133.1314 - r2_keras: 0.1384 - acc: 2.9700e-04 - val_loss: 247.9548 - val_r2_keras: -8.6041e-01 - val_acc: 0.0000e+00\n",
      "Epoch 13/500\n",
      "1s - loss: 140.8827 - r2_keras: 0.0753 - acc: 0.0000e+00 - val_loss: 80.3974 - val_r2_keras: 0.4589 - val_acc: 0.0012\n",
      "Epoch 14/500\n",
      "1s - loss: 151.7526 - r2_keras: 0.0033 - acc: 0.0012 - val_loss: 104.9897 - val_r2_keras: 0.3017 - val_acc: 0.0000e+00\n",
      "Epoch 15/500\n",
      "1s - loss: 163.6246 - r2_keras: -1.1194e-01 - acc: 2.9700e-04 - val_loss: 79.0447 - val_r2_keras: 0.4858 - val_acc: 0.0000e+00\n",
      "Epoch 16/500\n",
      "1s - loss: 124.5502 - r2_keras: 0.2084 - acc: 2.9700e-04 - val_loss: 413.0887 - val_r2_keras: -2.0199e+00 - val_acc: 0.0000e+00\n",
      "Epoch 17/500\n",
      "1s - loss: 139.5678 - r2_keras: 0.1111 - acc: 2.9700e-04 - val_loss: 109.3604 - val_r2_keras: 0.2676 - val_acc: 0.0012\n",
      "Epoch 18/500\n",
      "1s - loss: 130.9663 - r2_keras: 0.1045 - acc: 5.9400e-04 - val_loss: 95.5200 - val_r2_keras: 0.3371 - val_acc: 0.0000e+00\n",
      "Epoch 19/500\n",
      "1s - loss: 123.2036 - r2_keras: 0.1998 - acc: 0.0000e+00 - val_loss: 116.6634 - val_r2_keras: 0.1631 - val_acc: 0.0000e+00\n",
      "Epoch 20/500\n",
      "1s - loss: 121.7530 - r2_keras: 0.2110 - acc: 5.9400e-04 - val_loss: 82.8581 - val_r2_keras: 0.4576 - val_acc: 0.0024\n",
      "Epoch 21/500\n",
      "1s - loss: 146.9175 - r2_keras: 0.0468 - acc: 0.0000e+00 - val_loss: 78.2159 - val_r2_keras: 0.4879 - val_acc: 0.0000e+00\n",
      "Epoch 22/500\n",
      "1s - loss: 126.5908 - r2_keras: 0.1606 - acc: 2.9700e-04 - val_loss: 80.5338 - val_r2_keras: 0.4767 - val_acc: 0.0000e+00\n",
      "Epoch 00021: early stopping\n",
      "Fold 0: Score 0.472593\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 2722)              3707364   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 2722)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1361)              3706003   \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1361)              1853682   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1361)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1361)              1853682   \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1361)              1853682   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1361)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1361)              1853682   \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1361)              1853682   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1361)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 1362      \n",
      "=================================================================\n",
      "Total params: 16,683,139\n",
      "Trainable params: 16,683,139\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 3367 samples, validate on 842 samples\n",
      "Epoch 1/500\n",
      "1s - loss: 1079.2239 - r2_keras: -7.2595e+00 - acc: 0.0000e+00 - val_loss: 197.2989 - val_r2_keras: 0.0640 - val_acc: 0.0024\n",
      "Epoch 2/500\n",
      "1s - loss: 142.7079 - r2_keras: -2.0229e-02 - acc: 0.0000e+00 - val_loss: 184.2893 - val_r2_keras: 0.1399 - val_acc: 0.0000e+00\n",
      "Epoch 3/500\n",
      "1s - loss: 125.4411 - r2_keras: 0.1037 - acc: 0.0012 - val_loss: 124.0791 - val_r2_keras: 0.4551 - val_acc: 0.0000e+00\n",
      "Epoch 4/500\n",
      "1s - loss: 118.9652 - r2_keras: 0.1451 - acc: 2.9700e-04 - val_loss: 122.7757 - val_r2_keras: 0.4720 - val_acc: 0.0000e+00\n",
      "Epoch 5/500\n",
      "1s - loss: 124.4214 - r2_keras: 0.1145 - acc: 2.9700e-04 - val_loss: 885.3337 - val_r2_keras: -4.3077e+00 - val_acc: 0.0000e+00\n",
      "Epoch 6/500\n",
      "1s - loss: 174.2483 - r2_keras: -2.0552e-01 - acc: 5.9400e-04 - val_loss: 215.2280 - val_r2_keras: -5.7660e-02 - val_acc: 0.0000e+00\n",
      "Epoch 7/500\n",
      "1s - loss: 228.4358 - r2_keras: -6.9492e-01 - acc: 5.9400e-04 - val_loss: 340.3218 - val_r2_keras: -8.4449e-01 - val_acc: 0.0000e+00\n",
      "Epoch 8/500\n",
      "1s - loss: 170.7033 - r2_keras: -2.3134e-01 - acc: 5.9400e-04 - val_loss: 190.3608 - val_r2_keras: 0.0949 - val_acc: 0.0000e+00\n",
      "Epoch 9/500\n",
      "1s - loss: 113.4693 - r2_keras: 0.2025 - acc: 5.9400e-04 - val_loss: 181.1291 - val_r2_keras: 0.0228 - val_acc: 0.0000e+00\n",
      "Epoch 10/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1s - loss: 125.5088 - r2_keras: 0.1234 - acc: 2.9700e-04 - val_loss: 165.1468 - val_r2_keras: 0.1250 - val_acc: 0.0000e+00\n",
      "Epoch 11/500\n",
      "1s - loss: 128.4908 - r2_keras: 0.0759 - acc: 5.9400e-04 - val_loss: 188.1466 - val_r2_keras: 0.0935 - val_acc: 0.0012\n",
      "Epoch 12/500\n",
      "1s - loss: 120.8121 - r2_keras: 0.1372 - acc: 5.9400e-04 - val_loss: 121.2932 - val_r2_keras: 0.4861 - val_acc: 0.0012\n",
      "Epoch 13/500\n",
      "1s - loss: 128.0042 - r2_keras: 0.0864 - acc: 5.9400e-04 - val_loss: 158.2998 - val_r2_keras: 0.2910 - val_acc: 0.0000e+00\n",
      "Epoch 14/500\n",
      "1s - loss: 124.8266 - r2_keras: 0.1138 - acc: 0.0000e+00 - val_loss: 172.7059 - val_r2_keras: 0.0762 - val_acc: 0.0000e+00\n",
      "Epoch 15/500\n",
      "1s - loss: 124.6397 - r2_keras: 0.0733 - acc: 5.9400e-04 - val_loss: 143.7419 - val_r2_keras: 0.2941 - val_acc: 0.0000e+00\n",
      "Epoch 16/500\n",
      "1s - loss: 118.7729 - r2_keras: 0.1426 - acc: 2.9700e-04 - val_loss: 134.8091 - val_r2_keras: 0.3593 - val_acc: 0.0000e+00\n",
      "Epoch 17/500\n",
      "1s - loss: 112.0116 - r2_keras: 0.1980 - acc: 5.9400e-04 - val_loss: 220.0738 - val_r2_keras: -2.4693e-01 - val_acc: 0.0000e+00\n",
      "Epoch 18/500\n",
      "1s - loss: 139.1529 - r2_keras: -1.6441e-02 - acc: 0.0000e+00 - val_loss: 172.9670 - val_r2_keras: 0.0871 - val_acc: 0.0000e+00\n",
      "Epoch 19/500\n",
      "1s - loss: 118.4283 - r2_keras: 0.1274 - acc: 5.9400e-04 - val_loss: 139.2849 - val_r2_keras: 0.3330 - val_acc: 0.0012\n",
      "Epoch 20/500\n",
      "1s - loss: 117.8563 - r2_keras: 0.1612 - acc: 5.9400e-04 - val_loss: 130.9551 - val_r2_keras: 0.4143 - val_acc: 0.0000e+00\n",
      "Epoch 21/500\n",
      "1s - loss: 100.6643 - r2_keras: 0.2730 - acc: 2.9700e-04 - val_loss: 157.4870 - val_r2_keras: 0.3019 - val_acc: 0.0012\n",
      "Epoch 22/500\n",
      "1s - loss: 117.6213 - r2_keras: 0.1598 - acc: 0.0000e+00 - val_loss: 177.1585 - val_r2_keras: 0.1829 - val_acc: 0.0000e+00\n",
      "Epoch 23/500\n",
      "1s - loss: 123.9900 - r2_keras: 0.0866 - acc: 5.9400e-04 - val_loss: 126.7135 - val_r2_keras: 0.4377 - val_acc: 0.0000e+00\n",
      "Epoch 24/500\n",
      "1s - loss: 103.5844 - r2_keras: 0.2576 - acc: 2.9700e-04 - val_loss: 174.3244 - val_r2_keras: 0.1955 - val_acc: 0.0012\n",
      "Epoch 25/500\n",
      "1s - loss: 122.7893 - r2_keras: 0.1223 - acc: 5.9400e-04 - val_loss: 146.3672 - val_r2_keras: 0.2816 - val_acc: 0.0012\n",
      "Epoch 26/500\n",
      "1s - loss: 107.9495 - r2_keras: 0.2393 - acc: 0.0000e+00 - val_loss: 139.5466 - val_r2_keras: 0.3368 - val_acc: 0.0000e+00\n",
      "Epoch 27/500\n",
      "1s - loss: 109.4151 - r2_keras: 0.1815 - acc: 0.0000e+00 - val_loss: 129.4266 - val_r2_keras: 0.4259 - val_acc: 0.0000e+00\n",
      "Epoch 28/500\n",
      "1s - loss: 93.4162 - r2_keras: 0.3427 - acc: 2.9700e-04 - val_loss: 125.7154 - val_r2_keras: 0.4455 - val_acc: 0.0000e+00\n",
      "Epoch 29/500\n",
      "1s - loss: 120.6643 - r2_keras: 0.1276 - acc: 0.0000e+00 - val_loss: 119.9421 - val_r2_keras: 0.4876 - val_acc: 0.0000e+00\n",
      "Epoch 30/500\n",
      "1s - loss: 108.2307 - r2_keras: 0.2186 - acc: 0.0000e+00 - val_loss: 130.3470 - val_r2_keras: 0.4207 - val_acc: 0.0000e+00\n",
      "Epoch 31/500\n",
      "1s - loss: 91.2170 - r2_keras: 0.3540 - acc: 5.9400e-04 - val_loss: 136.1277 - val_r2_keras: 0.3532 - val_acc: 0.0000e+00\n",
      "Epoch 32/500\n",
      "1s - loss: 100.3216 - r2_keras: 0.2780 - acc: 0.0012 - val_loss: 126.9468 - val_r2_keras: 0.4284 - val_acc: 0.0012\n",
      "Epoch 33/500\n",
      "1s - loss: 97.2261 - r2_keras: 0.3169 - acc: 0.0012 - val_loss: 130.4876 - val_r2_keras: 0.4472 - val_acc: 0.0036\n",
      "Epoch 34/500\n",
      "1s - loss: 91.8937 - r2_keras: 0.3522 - acc: 2.9700e-04 - val_loss: 150.9055 - val_r2_keras: 0.3280 - val_acc: 0.0012\n",
      "Epoch 35/500\n",
      "1s - loss: 105.8537 - r2_keras: 0.2327 - acc: 5.9400e-04 - val_loss: 147.6039 - val_r2_keras: 0.3512 - val_acc: 0.0012\n",
      "Epoch 36/500\n",
      "1s - loss: 99.6741 - r2_keras: 0.2898 - acc: 0.0015 - val_loss: 125.7915 - val_r2_keras: 0.4565 - val_acc: 0.0024\n",
      "Epoch 37/500\n",
      "1s - loss: 101.4629 - r2_keras: 0.2898 - acc: 2.9700e-04 - val_loss: 213.1234 - val_r2_keras: -5.2365e-02 - val_acc: 0.0000e+00\n",
      "Epoch 38/500\n",
      "1s - loss: 104.3994 - r2_keras: 0.2471 - acc: 0.0000e+00 - val_loss: 131.1194 - val_r2_keras: 0.4466 - val_acc: 0.0048\n",
      "Epoch 39/500\n",
      "1s - loss: 99.7723 - r2_keras: 0.2812 - acc: 5.9400e-04 - val_loss: 212.7039 - val_r2_keras: -4.8245e-02 - val_acc: 0.0000e+00\n",
      "Epoch 40/500\n",
      "1s - loss: 104.3866 - r2_keras: 0.2481 - acc: 8.9100e-04 - val_loss: 154.4430 - val_r2_keras: 0.3055 - val_acc: 0.0048\n",
      "Epoch 41/500\n",
      "1s - loss: 103.3946 - r2_keras: 0.2650 - acc: 5.9400e-04 - val_loss: 217.1136 - val_r2_keras: -8.0169e-02 - val_acc: 0.0000e+00\n",
      "Epoch 42/500\n",
      "1s - loss: 95.0742 - r2_keras: 0.3087 - acc: 2.9700e-04 - val_loss: 155.6937 - val_r2_keras: 0.2294 - val_acc: 0.0000e+00\n",
      "Epoch 43/500\n",
      "1s - loss: 98.6039 - r2_keras: 0.2910 - acc: 2.9700e-04 - val_loss: 128.1905 - val_r2_keras: 0.4252 - val_acc: 0.0000e+00\n",
      "Epoch 44/500\n",
      "1s - loss: 99.3963 - r2_keras: 0.2909 - acc: 5.9400e-04 - val_loss: 123.6692 - val_r2_keras: 0.4637 - val_acc: 0.0000e+00\n",
      "Epoch 45/500\n",
      "1s - loss: 95.5105 - r2_keras: 0.3113 - acc: 5.9400e-04 - val_loss: 125.8331 - val_r2_keras: 0.4581 - val_acc: 0.0036\n",
      "Epoch 46/500\n",
      "1s - loss: 86.2339 - r2_keras: 0.3879 - acc: 2.9700e-04 - val_loss: 140.7483 - val_r2_keras: 0.3337 - val_acc: 0.0000e+00\n",
      "Epoch 47/500\n",
      "1s - loss: 117.2389 - r2_keras: 0.1845 - acc: 0.0000e+00 - val_loss: 125.6745 - val_r2_keras: 0.4694 - val_acc: 0.0012\n",
      "Epoch 48/500\n",
      "1s - loss: 88.1573 - r2_keras: 0.3581 - acc: 5.9400e-04 - val_loss: 141.5419 - val_r2_keras: 0.3399 - val_acc: 0.0012\n",
      "Epoch 49/500\n",
      "1s - loss: 86.5982 - r2_keras: 0.3770 - acc: 2.9700e-04 - val_loss: 129.8833 - val_r2_keras: 0.4551 - val_acc: 0.0024\n",
      "Epoch 50/500\n",
      "1s - loss: 80.1719 - r2_keras: 0.4219 - acc: 2.9700e-04 - val_loss: 132.6876 - val_r2_keras: 0.4371 - val_acc: 0.0036\n",
      "Epoch 00049: early stopping\n",
      "Fold 1: Score 0.349713\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 2722)              3707364   \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 2722)              0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1361)              3706003   \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1361)              1853682   \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 1361)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1361)              1853682   \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1361)              1853682   \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 1361)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1361)              1853682   \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1361)              1853682   \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 1361)              0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 1362      \n",
      "=================================================================\n",
      "Total params: 16,683,139\n",
      "Trainable params: 16,683,139\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 3367 samples, validate on 842 samples\n",
      "Epoch 1/500\n",
      "2s - loss: 1992.7221 - r2_keras: -1.3553e+01 - acc: 5.9400e-04 - val_loss: 71.5524 - val_r2_keras: 0.5314 - val_acc: 0.0000e+00\n",
      "Epoch 2/500\n",
      "1s - loss: 151.3793 - r2_keras: 0.0132 - acc: 0.0000e+00 - val_loss: 137.1674 - val_r2_keras: 0.0982 - val_acc: 0.0000e+00\n",
      "Epoch 3/500\n",
      "2s - loss: 142.3911 - r2_keras: 0.0857 - acc: 2.9700e-04 - val_loss: 70.9691 - val_r2_keras: 0.5070 - val_acc: 0.0000e+00\n",
      "Epoch 4/500\n",
      "1s - loss: 135.2600 - r2_keras: 0.1217 - acc: 2.9700e-04 - val_loss: 92.7465 - val_r2_keras: 0.4053 - val_acc: 0.0000e+00\n",
      "Epoch 5/500\n",
      "1s - loss: 139.3001 - r2_keras: 0.0953 - acc: 8.9100e-04 - val_loss: 173.6574 - val_r2_keras: -3.6190e-01 - val_acc: 0.0000e+00\n",
      "Epoch 6/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1s - loss: 157.6646 - r2_keras: -7.6453e-03 - acc: 2.9700e-04 - val_loss: 132.9445 - val_r2_keras: -2.6739e-03 - val_acc: 0.0012\n",
      "Epoch 7/500\n",
      "1s - loss: 166.3111 - r2_keras: -1.0063e-01 - acc: 5.9400e-04 - val_loss: 193.7002 - val_r2_keras: -3.1743e-01 - val_acc: 0.0000e+00\n",
      "Epoch 8/500\n",
      "2s - loss: 132.9071 - r2_keras: 0.1470 - acc: 8.9100e-04 - val_loss: 68.6994 - val_r2_keras: 0.5369 - val_acc: 0.0012\n",
      "Epoch 9/500\n",
      "1s - loss: 128.7431 - r2_keras: 0.1708 - acc: 5.9400e-04 - val_loss: 76.1954 - val_r2_keras: 0.4820 - val_acc: 0.0012\n",
      "Epoch 10/500\n",
      "1s - loss: 120.4643 - r2_keras: 0.2255 - acc: 0.0000e+00 - val_loss: 108.9599 - val_r2_keras: 0.1898 - val_acc: 0.0000e+00\n",
      "Epoch 11/500\n",
      "1s - loss: 132.2828 - r2_keras: 0.1459 - acc: 5.9400e-04 - val_loss: 125.7133 - val_r2_keras: 0.1637 - val_acc: 0.0000e+00\n",
      "Epoch 12/500\n",
      "1s - loss: 134.5517 - r2_keras: 0.1305 - acc: 5.9400e-04 - val_loss: 78.0212 - val_r2_keras: 0.4986 - val_acc: 0.0012\n",
      "Epoch 13/500\n",
      "1s - loss: 134.2671 - r2_keras: 0.1343 - acc: 0.0000e+00 - val_loss: 87.8893 - val_r2_keras: 0.4316 - val_acc: 0.0000e+00\n",
      "Epoch 14/500\n",
      "1s - loss: 119.2257 - r2_keras: 0.2211 - acc: 2.9700e-04 - val_loss: 68.8203 - val_r2_keras: 0.5550 - val_acc: 0.0000e+00\n",
      "Epoch 15/500\n",
      "1s - loss: 149.8808 - r2_keras: -7.9510e-03 - acc: 8.9100e-04 - val_loss: 151.7050 - val_r2_keras: -1.7421e-01 - val_acc: 0.0000e+00\n",
      "Epoch 16/500\n",
      "1s - loss: 146.6443 - r2_keras: 0.0289 - acc: 2.9700e-04 - val_loss: 86.0963 - val_r2_keras: 0.3771 - val_acc: 0.0000e+00\n",
      "Epoch 17/500\n",
      "1s - loss: 131.9690 - r2_keras: 0.1210 - acc: 5.9400e-04 - val_loss: 70.9813 - val_r2_keras: 0.4868 - val_acc: 0.0000e+00\n",
      "Epoch 18/500\n",
      "1s - loss: 124.7727 - r2_keras: 0.1976 - acc: 0.0000e+00 - val_loss: 113.3715 - val_r2_keras: 0.2517 - val_acc: 0.0000e+00\n",
      "Epoch 19/500\n",
      "1s - loss: 132.0158 - r2_keras: 0.1526 - acc: 2.9700e-04 - val_loss: 77.7709 - val_r2_keras: 0.4990 - val_acc: 0.0000e+00\n",
      "Epoch 20/500\n",
      "1s - loss: 120.5896 - r2_keras: 0.2259 - acc: 2.9700e-04 - val_loss: 69.7638 - val_r2_keras: 0.5388 - val_acc: 0.0012\n",
      "Epoch 21/500\n",
      "1s - loss: 120.5037 - r2_keras: 0.1998 - acc: 2.9700e-04 - val_loss: 95.3485 - val_r2_keras: 0.3834 - val_acc: 0.0000e+00\n",
      "Epoch 22/500\n",
      "1s - loss: 119.2899 - r2_keras: 0.2404 - acc: 2.9700e-04 - val_loss: 71.1090 - val_r2_keras: 0.5436 - val_acc: 0.0000e+00\n",
      "Epoch 23/500\n",
      "1s - loss: 111.8190 - r2_keras: 0.2760 - acc: 0.0012 - val_loss: 180.6985 - val_r2_keras: -2.3324e-01 - val_acc: 0.0000e+00\n",
      "Epoch 24/500\n",
      "1s - loss: 126.3863 - r2_keras: 0.1888 - acc: 0.0000e+00 - val_loss: 69.9174 - val_r2_keras: 0.5247 - val_acc: 0.0000e+00\n",
      "Epoch 25/500\n",
      "1s - loss: 130.2679 - r2_keras: 0.1677 - acc: 0.0000e+00 - val_loss: 70.3195 - val_r2_keras: 0.5500 - val_acc: 0.0000e+00\n",
      "Epoch 26/500\n",
      "1s - loss: 112.5273 - r2_keras: 0.2720 - acc: 2.9700e-04 - val_loss: 75.4386 - val_r2_keras: 0.4480 - val_acc: 0.0000e+00\n",
      "Epoch 27/500\n",
      "1s - loss: 114.0071 - r2_keras: 0.2886 - acc: 8.9100e-04 - val_loss: 104.2943 - val_r2_keras: 0.3177 - val_acc: 0.0000e+00\n",
      "Epoch 28/500\n",
      "1s - loss: 117.2027 - r2_keras: 0.2475 - acc: 5.9400e-04 - val_loss: 98.2405 - val_r2_keras: 0.2801 - val_acc: 0.0000e+00\n",
      "Epoch 29/500\n",
      "2s - loss: 119.3429 - r2_keras: 0.2134 - acc: 2.9700e-04 - val_loss: 66.7929 - val_r2_keras: 0.5481 - val_acc: 0.0012\n",
      "Epoch 30/500\n",
      "1s - loss: 118.9369 - r2_keras: 0.2254 - acc: 0.0012 - val_loss: 68.0837 - val_r2_keras: 0.5516 - val_acc: 0.0000e+00\n",
      "Epoch 31/500\n",
      "1s - loss: 112.7273 - r2_keras: 0.2757 - acc: 2.9700e-04 - val_loss: 95.8471 - val_r2_keras: 0.3820 - val_acc: 0.0012\n",
      "Epoch 32/500\n",
      "1s - loss: 117.0570 - r2_keras: 0.2353 - acc: 8.9100e-04 - val_loss: 108.3628 - val_r2_keras: 0.2947 - val_acc: 0.0000e+00\n",
      "Epoch 33/500\n",
      "1s - loss: 105.7964 - r2_keras: 0.3204 - acc: 2.9700e-04 - val_loss: 130.9184 - val_r2_keras: 0.1367 - val_acc: 0.0012\n",
      "Epoch 34/500\n",
      "1s - loss: 113.2279 - r2_keras: 0.2628 - acc: 5.9400e-04 - val_loss: 71.5115 - val_r2_keras: 0.5093 - val_acc: 0.0012\n",
      "Epoch 35/500\n",
      "1s - loss: 102.0332 - r2_keras: 0.3434 - acc: 2.9700e-04 - val_loss: 81.1317 - val_r2_keras: 0.4813 - val_acc: 0.0012\n",
      "Epoch 36/500\n",
      "1s - loss: 104.7813 - r2_keras: 0.2956 - acc: 0.0000e+00 - val_loss: 143.2805 - val_r2_keras: -9.8903e-02 - val_acc: 0.0000e+00\n",
      "Epoch 37/500\n",
      "1s - loss: 111.5746 - r2_keras: 0.2605 - acc: 5.9400e-04 - val_loss: 69.2455 - val_r2_keras: 0.5515 - val_acc: 0.0000e+00\n",
      "Epoch 38/500\n",
      "1s - loss: 124.9345 - r2_keras: 0.1831 - acc: 0.0000e+00 - val_loss: 82.3041 - val_r2_keras: 0.4197 - val_acc: 0.0000e+00\n",
      "Epoch 39/500\n",
      "1s - loss: 101.4238 - r2_keras: 0.3477 - acc: 0.0000e+00 - val_loss: 190.6980 - val_r2_keras: -4.7871e-01 - val_acc: 0.0000e+00\n",
      "Epoch 40/500\n",
      "1s - loss: 112.1736 - r2_keras: 0.2689 - acc: 0.0012 - val_loss: 91.6651 - val_r2_keras: 0.4050 - val_acc: 0.0012\n",
      "Epoch 41/500\n",
      "1s - loss: 111.1272 - r2_keras: 0.2696 - acc: 5.9400e-04 - val_loss: 72.7218 - val_r2_keras: 0.5328 - val_acc: 0.0000e+00\n",
      "Epoch 42/500\n",
      "1s - loss: 119.1105 - r2_keras: 0.2152 - acc: 2.9700e-04 - val_loss: 125.6136 - val_r2_keras: 0.1687 - val_acc: 0.0012\n",
      "Epoch 43/500\n",
      "1s - loss: 97.0233 - r2_keras: 0.3696 - acc: 2.9700e-04 - val_loss: 72.3152 - val_r2_keras: 0.5282 - val_acc: 0.0012\n",
      "Epoch 44/500\n",
      "1s - loss: 100.6780 - r2_keras: 0.3450 - acc: 2.9700e-04 - val_loss: 157.8510 - val_r2_keras: -2.2925e-01 - val_acc: 0.0000e+00\n",
      "Epoch 45/500\n",
      "1s - loss: 102.7776 - r2_keras: 0.3162 - acc: 5.9400e-04 - val_loss: 105.4923 - val_r2_keras: 0.3067 - val_acc: 0.0000e+00\n",
      "Epoch 46/500\n",
      "1s - loss: 105.6654 - r2_keras: 0.3059 - acc: 2.9700e-04 - val_loss: 78.6608 - val_r2_keras: 0.4919 - val_acc: 0.0012\n",
      "Epoch 47/500\n",
      "1s - loss: 110.0461 - r2_keras: 0.2786 - acc: 5.9400e-04 - val_loss: 108.4315 - val_r2_keras: 0.2917 - val_acc: 0.0000e+00\n",
      "Epoch 48/500\n",
      "1s - loss: 101.9837 - r2_keras: 0.3384 - acc: 8.9100e-04 - val_loss: 93.0917 - val_r2_keras: 0.3064 - val_acc: 0.0000e+00\n",
      "Epoch 49/500\n",
      "1s - loss: 89.9226 - r2_keras: 0.4145 - acc: 2.9700e-04 - val_loss: 77.5370 - val_r2_keras: 0.4431 - val_acc: 0.0000e+00\n",
      "Epoch 50/500\n",
      "1s - loss: 98.3061 - r2_keras: 0.3516 - acc: 5.9400e-04 - val_loss: 83.8829 - val_r2_keras: 0.4549 - val_acc: 0.0012\n",
      "Epoch 00049: early stopping\n",
      "Fold 2: Score 0.449656\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 2722)              3707364   \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 2722)              0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1361)              3706003   \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1361)              1853682   \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 1361)              0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1361)              1853682   \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1361)              1853682   \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 1361)              0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1361)              1853682   \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 1361)              1853682   \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 1361)              0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 1)                 1362      \n",
      "=================================================================\n",
      "Total params: 16,683,139\n",
      "Trainable params: 16,683,139\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 3367 samples, validate on 842 samples\n",
      "Epoch 1/500\n",
      "1s - loss: 590.9643 - r2_keras: -3.3039e+00 - acc: 5.9400e-04 - val_loss: 211.1277 - val_r2_keras: -4.0724e-01 - val_acc: 0.0000e+00\n",
      "Epoch 2/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1s - loss: 150.9128 - r2_keras: 0.0074 - acc: 0.0000e+00 - val_loss: 241.8384 - val_r2_keras: -6.2594e-01 - val_acc: 0.0000e+00\n",
      "Epoch 3/500\n",
      "1s - loss: 152.3302 - r2_keras: 0.0023 - acc: 2.9700e-04 - val_loss: 201.3059 - val_r2_keras: -3.4070e-01 - val_acc: 0.0000e+00\n",
      "Epoch 4/500\n",
      "1s - loss: 160.6701 - r2_keras: -8.4098e-02 - acc: 5.9400e-04 - val_loss: 202.6741 - val_r2_keras: -3.5687e-01 - val_acc: 0.0000e+00\n",
      "Epoch 5/500\n",
      "1s - loss: 197.2720 - r2_keras: -4.0707e-01 - acc: 0.0012 - val_loss: 109.0673 - val_r2_keras: 0.2629 - val_acc: 0.0012\n",
      "Epoch 6/500\n",
      "1s - loss: 169.8638 - r2_keras: -1.5974e-01 - acc: 5.9400e-04 - val_loss: 94.7239 - val_r2_keras: 0.3908 - val_acc: 0.0012\n",
      "Epoch 7/500\n",
      "1s - loss: 146.0903 - r2_keras: 0.0652 - acc: 5.9400e-04 - val_loss: 391.4241 - val_r2_keras: -1.7588e+00 - val_acc: 0.0000e+00\n",
      "Epoch 8/500\n",
      "1s - loss: 171.8905 - r2_keras: -1.6255e-01 - acc: 5.9400e-04 - val_loss: 117.1587 - val_r2_keras: 0.2330 - val_acc: 0.0000e+00\n",
      "Epoch 9/500\n",
      "1s - loss: 141.5994 - r2_keras: 0.0497 - acc: 0.0000e+00 - val_loss: 164.1382 - val_r2_keras: -8.3136e-02 - val_acc: 0.0000e+00\n",
      "Epoch 10/500\n",
      "1s - loss: 150.4483 - r2_keras: 0.0134 - acc: 5.9400e-04 - val_loss: 193.6490 - val_r2_keras: -3.5365e-01 - val_acc: 0.0000e+00\n",
      "Epoch 11/500\n",
      "1s - loss: 174.2274 - r2_keras: -1.7138e-01 - acc: 0.0000e+00 - val_loss: 96.9812 - val_r2_keras: 0.3700 - val_acc: 0.0012\n",
      "Epoch 12/500\n",
      "1s - loss: 164.7439 - r2_keras: -1.0129e-01 - acc: 5.9400e-04 - val_loss: 81.5626 - val_r2_keras: 0.4625 - val_acc: 0.0000e+00\n",
      "Epoch 13/500\n",
      "1s - loss: 171.1997 - r2_keras: -1.5020e-01 - acc: 2.9700e-04 - val_loss: 156.2634 - val_r2_keras: -3.2757e-02 - val_acc: 0.0000e+00\n",
      "Epoch 14/500\n",
      "1s - loss: 142.3981 - r2_keras: 0.0649 - acc: 5.9400e-04 - val_loss: 79.3618 - val_r2_keras: 0.4791 - val_acc: 0.0000e+00\n",
      "Epoch 15/500\n",
      "1s - loss: 124.0431 - r2_keras: 0.1773 - acc: 0.0015 - val_loss: 78.3812 - val_r2_keras: 0.4878 - val_acc: 0.0024\n",
      "Epoch 16/500\n",
      "1s - loss: 122.9535 - r2_keras: 0.2154 - acc: 8.9100e-04 - val_loss: 85.1506 - val_r2_keras: 0.4469 - val_acc: 0.0000e+00\n",
      "Epoch 17/500\n",
      "1s - loss: 110.6719 - r2_keras: 0.3040 - acc: 5.9400e-04 - val_loss: 101.1231 - val_r2_keras: 0.3410 - val_acc: 0.0000e+00\n",
      "Epoch 18/500\n",
      "1s - loss: 146.6754 - r2_keras: 0.0042 - acc: 2.9700e-04 - val_loss: 82.7273 - val_r2_keras: 0.4673 - val_acc: 0.0024\n",
      "Epoch 19/500\n",
      "1s - loss: 132.4972 - r2_keras: 0.1279 - acc: 0.0000e+00 - val_loss: 88.5741 - val_r2_keras: 0.4042 - val_acc: 0.0000e+00\n",
      "Epoch 20/500\n",
      "1s - loss: 125.9078 - r2_keras: 0.1729 - acc: 2.9700e-04 - val_loss: 155.1075 - val_r2_keras: -2.0133e-02 - val_acc: 0.0000e+00\n",
      "Epoch 21/500\n",
      "1s - loss: 113.9936 - r2_keras: 0.2518 - acc: 5.9400e-04 - val_loss: 80.0303 - val_r2_keras: 0.4714 - val_acc: 0.0012\n",
      "Epoch 22/500\n",
      "1s - loss: 120.9611 - r2_keras: 0.2130 - acc: 5.9400e-04 - val_loss: 89.9802 - val_r2_keras: 0.3948 - val_acc: 0.0000e+00\n",
      "Epoch 23/500\n",
      "1s - loss: 125.6577 - r2_keras: 0.1835 - acc: 0.0012 - val_loss: 122.8075 - val_r2_keras: 0.1619 - val_acc: 0.0000e+00\n",
      "Epoch 24/500\n",
      "1s - loss: 119.6507 - r2_keras: 0.2183 - acc: 8.9100e-04 - val_loss: 83.1319 - val_r2_keras: 0.4497 - val_acc: 0.0024\n",
      "Epoch 25/500\n",
      "1s - loss: 125.0232 - r2_keras: 0.1865 - acc: 8.9100e-04 - val_loss: 148.2873 - val_r2_keras: 0.0213 - val_acc: 0.0000e+00\n",
      "Epoch 26/500\n",
      "1s - loss: 141.0249 - r2_keras: 0.0024 - acc: 5.9400e-04 - val_loss: 84.1189 - val_r2_keras: 0.4494 - val_acc: 0.0000e+00\n",
      "Epoch 27/500\n",
      "1s - loss: 129.7597 - r2_keras: 0.1476 - acc: 2.9700e-04 - val_loss: 222.5709 - val_r2_keras: -5.6123e-01 - val_acc: 0.0000e+00\n",
      "Epoch 28/500\n",
      "1s - loss: 136.0997 - r2_keras: 0.1112 - acc: 2.9700e-04 - val_loss: 89.7675 - val_r2_keras: 0.4154 - val_acc: 0.0012\n",
      "Epoch 29/500\n",
      "1s - loss: 123.1941 - r2_keras: 0.1892 - acc: 0.0000e+00 - val_loss: 186.4697 - val_r2_keras: -2.4171e-01 - val_acc: 0.0000e+00\n",
      "Epoch 30/500\n",
      "1s - loss: 127.7126 - r2_keras: 0.1593 - acc: 5.9400e-04 - val_loss: 157.7665 - val_r2_keras: -9.6509e-02 - val_acc: 0.0000e+00\n",
      "Epoch 31/500\n",
      "1s - loss: 113.7390 - r2_keras: 0.2602 - acc: 0.0000e+00 - val_loss: 91.0790 - val_r2_keras: 0.4065 - val_acc: 0.0024\n",
      "Epoch 32/500\n",
      "1s - loss: 114.8390 - r2_keras: 0.2527 - acc: 2.9700e-04 - val_loss: 89.1907 - val_r2_keras: 0.4105 - val_acc: 0.0000e+00\n",
      "Epoch 33/500\n",
      "1s - loss: 107.0238 - r2_keras: 0.3035 - acc: 8.9100e-04 - val_loss: 183.7310 - val_r2_keras: -2.7794e-01 - val_acc: 0.0000e+00\n",
      "Epoch 34/500\n",
      "1s - loss: 112.5148 - r2_keras: 0.2627 - acc: 5.9400e-04 - val_loss: 82.2378 - val_r2_keras: 0.4656 - val_acc: 0.0000e+00\n",
      "Epoch 35/500\n",
      "1s - loss: 125.2108 - r2_keras: 0.1804 - acc: 2.9700e-04 - val_loss: 84.8732 - val_r2_keras: 0.4481 - val_acc: 0.0024\n",
      "Epoch 36/500\n",
      "1s - loss: 130.2042 - r2_keras: 0.1628 - acc: 2.9700e-04 - val_loss: 114.8037 - val_r2_keras: 0.2170 - val_acc: 0.0000e+00\n",
      "Epoch 00035: early stopping\n",
      "Fold 3: Score 0.276070\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_33 (Dense)             (None, 2722)              3707364   \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 2722)              0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1361)              3706003   \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 1361)              1853682   \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 1361)              0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1361)              1853682   \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 1361)              1853682   \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 1361)              0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 1361)              1853682   \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1361)              1853682   \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 1361)              0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 1)                 1362      \n",
      "=================================================================\n",
      "Total params: 16,683,139\n",
      "Trainable params: 16,683,139\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 3368 samples, validate on 841 samples\n",
      "Epoch 1/500\n",
      "1s - loss: 1290.8442 - r2_keras: -7.3452e+00 - acc: 0.0000e+00 - val_loss: 69.0752 - val_r2_keras: -1.8985e+06 - val_acc: 0.0012\n",
      "Epoch 2/500\n",
      "2s - loss: 139.9288 - r2_keras: 0.1153 - acc: 2.9691e-04 - val_loss: 58.1262 - val_r2_keras: -4.5587e+06 - val_acc: 0.0012\n",
      "Epoch 3/500\n",
      "1s - loss: 153.9327 - r2_keras: 0.0415 - acc: 0.0015 - val_loss: 98.6044 - val_r2_keras: -1.3966e+06 - val_acc: 0.0000e+00\n",
      "Epoch 4/500\n",
      "1s - loss: 151.7728 - r2_keras: 0.0328 - acc: 0.0000e+00 - val_loss: 96.9298 - val_r2_keras: -5.6851e+06 - val_acc: 0.0000e+00\n",
      "Epoch 5/500\n",
      "1s - loss: 187.9609 - r2_keras: -2.1235e-01 - acc: 8.9074e-04 - val_loss: 58.5765 - val_r2_keras: -2.4433e+06 - val_acc: 0.0000e+00\n",
      "Epoch 6/500\n",
      "1s - loss: 144.4958 - r2_keras: 0.0988 - acc: 5.9382e-04 - val_loss: 160.0533 - val_r2_keras: -9.3341e+05 - val_acc: 0.0000e+00\n",
      "Epoch 7/500\n",
      "1s - loss: 147.7124 - r2_keras: 0.0339 - acc: 0.0012 - val_loss: 63.0031 - val_r2_keras: -3.9762e+06 - val_acc: 0.0000e+00\n",
      "Epoch 8/500\n",
      "1s - loss: 155.7019 - r2_keras: 0.0177 - acc: 8.9074e-04 - val_loss: 191.5056 - val_r2_keras: -9.6463e+06 - val_acc: 0.0000e+00\n",
      "Epoch 9/500\n",
      "1s - loss: 199.1416 - r2_keras: -2.5624e-01 - acc: 5.9382e-04 - val_loss: 58.7694 - val_r2_keras: -3.9406e+06 - val_acc: 0.0000e+00\n",
      "Epoch 10/500\n",
      "1s - loss: 154.0446 - r2_keras: -2.2017e-02 - acc: 8.9074e-04 - val_loss: 59.7650 - val_r2_keras: -2.5498e+06 - val_acc: 0.0000e+00\n",
      "Epoch 11/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1s - loss: 184.2349 - r2_keras: -2.1835e-01 - acc: 2.9691e-04 - val_loss: 477.3634 - val_r2_keras: -8.4326e+02 - val_acc: 0.0000e+00\n",
      "Epoch 12/500\n",
      "1s - loss: 169.7698 - r2_keras: -1.0110e-01 - acc: 0.0012 - val_loss: 140.7335 - val_r2_keras: -5.1904e+05 - val_acc: 0.0000e+00\n",
      "Epoch 13/500\n",
      "1s - loss: 174.8109 - r2_keras: -1.5374e-01 - acc: 0.0000e+00 - val_loss: 69.5287 - val_r2_keras: -5.1354e+06 - val_acc: 0.0000e+00\n",
      "Epoch 14/500\n",
      "1s - loss: 149.7524 - r2_keras: 0.0329 - acc: 0.0000e+00 - val_loss: 79.7517 - val_r2_keras: -5.5929e+06 - val_acc: 0.0000e+00\n",
      "Epoch 15/500\n",
      "1s - loss: 138.9988 - r2_keras: 0.1076 - acc: 8.9074e-04 - val_loss: 77.6357 - val_r2_keras: -5.5597e+06 - val_acc: 0.0000e+00\n",
      "Epoch 16/500\n",
      "1s - loss: 146.8805 - r2_keras: 0.0647 - acc: 2.9691e-04 - val_loss: 58.9280 - val_r2_keras: -3.1335e+06 - val_acc: 0.0000e+00\n",
      "Epoch 17/500\n",
      "1s - loss: 146.0133 - r2_keras: 0.0922 - acc: 5.9382e-04 - val_loss: 69.6111 - val_r2_keras: -2.4547e+06 - val_acc: 0.0000e+00\n",
      "Epoch 18/500\n",
      "1s - loss: 135.8776 - r2_keras: 0.1501 - acc: 2.9691e-04 - val_loss: 84.5632 - val_r2_keras: -6.8962e+06 - val_acc: 0.0000e+00\n",
      "Epoch 19/500\n",
      "2s - loss: 141.6926 - r2_keras: 0.1010 - acc: 2.9691e-04 - val_loss: 53.9750 - val_r2_keras: -3.4232e+06 - val_acc: 0.0000e+00\n",
      "Epoch 20/500\n",
      "1s - loss: 122.6723 - r2_keras: 0.2264 - acc: 2.9691e-04 - val_loss: 164.7551 - val_r2_keras: -8.5989e+06 - val_acc: 0.0012\n",
      "Epoch 21/500\n",
      "1s - loss: 147.4491 - r2_keras: 0.0440 - acc: 8.9074e-04 - val_loss: 71.9321 - val_r2_keras: -2.0086e+06 - val_acc: 0.0000e+00\n",
      "Epoch 22/500\n",
      "1s - loss: 133.5310 - r2_keras: 0.1219 - acc: 0.0000e+00 - val_loss: 71.9365 - val_r2_keras: -4.1248e+06 - val_acc: 0.0000e+00\n",
      "Epoch 23/500\n",
      "1s - loss: 135.2337 - r2_keras: 0.1383 - acc: 2.9691e-04 - val_loss: 65.0429 - val_r2_keras: -2.4250e+06 - val_acc: 0.0000e+00\n",
      "Epoch 24/500\n",
      "1s - loss: 130.4065 - r2_keras: 0.1755 - acc: 5.9382e-04 - val_loss: 62.4209 - val_r2_keras: -4.7154e+06 - val_acc: 0.0000e+00\n",
      "Epoch 25/500\n",
      "1s - loss: 133.0151 - r2_keras: 0.1445 - acc: 5.9382e-04 - val_loss: 71.6446 - val_r2_keras: -5.3330e+06 - val_acc: 0.0000e+00\n",
      "Epoch 26/500\n",
      "1s - loss: 128.3179 - r2_keras: 0.2083 - acc: 0.0000e+00 - val_loss: 57.7061 - val_r2_keras: -3.4546e+06 - val_acc: 0.0000e+00\n",
      "Epoch 27/500\n",
      "1s - loss: 134.4470 - r2_keras: 0.1569 - acc: 8.9074e-04 - val_loss: 60.4608 - val_r2_keras: -3.8544e+06 - val_acc: 0.0000e+00\n",
      "Epoch 28/500\n",
      "1s - loss: 142.3265 - r2_keras: 0.1108 - acc: 2.9691e-04 - val_loss: 55.3251 - val_r2_keras: -3.8907e+06 - val_acc: 0.0024\n",
      "Epoch 29/500\n",
      "1s - loss: 127.8562 - r2_keras: 0.1871 - acc: 2.9691e-04 - val_loss: 91.5103 - val_r2_keras: -5.1929e+06 - val_acc: 0.0000e+00\n",
      "Epoch 30/500\n",
      "1s - loss: 128.8595 - r2_keras: 0.1778 - acc: 2.9691e-04 - val_loss: 100.3618 - val_r2_keras: -4.6165e+06 - val_acc: 0.0012\n",
      "Epoch 31/500\n",
      "1s - loss: 130.8477 - r2_keras: 0.1716 - acc: 8.9074e-04 - val_loss: 58.2169 - val_r2_keras: -1.9047e+06 - val_acc: 0.0000e+00\n",
      "Epoch 32/500\n",
      "2s - loss: 131.0256 - r2_keras: 0.1933 - acc: 8.9074e-04 - val_loss: 51.1144 - val_r2_keras: -3.2607e+06 - val_acc: 0.0012\n",
      "Epoch 33/500\n",
      "1s - loss: 111.8949 - r2_keras: 0.3068 - acc: 8.9074e-04 - val_loss: 114.0318 - val_r2_keras: -8.2600e+05 - val_acc: 0.0000e+00\n",
      "Epoch 34/500\n",
      "1s - loss: 119.5786 - r2_keras: 0.2526 - acc: 2.9691e-04 - val_loss: 101.9507 - val_r2_keras: -5.8307e+06 - val_acc: 0.0000e+00\n",
      "Epoch 35/500\n",
      "1s - loss: 127.0226 - r2_keras: 0.1925 - acc: 2.9691e-04 - val_loss: 57.3460 - val_r2_keras: -4.2730e+06 - val_acc: 0.0012\n",
      "Epoch 36/500\n",
      "1s - loss: 128.2613 - r2_keras: 0.1763 - acc: 2.9691e-04 - val_loss: 202.3760 - val_r2_keras: -1.4622e+05 - val_acc: 0.0000e+00\n",
      "Epoch 37/500\n",
      "1s - loss: 149.1463 - r2_keras: 0.0403 - acc: 0.0012 - val_loss: 175.7017 - val_r2_keras: -7.7191e+06 - val_acc: 0.0000e+00\n",
      "Epoch 38/500\n",
      "1s - loss: 124.2621 - r2_keras: 0.2091 - acc: 2.9691e-04 - val_loss: 280.4318 - val_r2_keras: -1.3108e+05 - val_acc: 0.0000e+00\n",
      "Epoch 39/500\n",
      "1s - loss: 130.5129 - r2_keras: 0.1397 - acc: 2.9691e-04 - val_loss: 157.5247 - val_r2_keras: -3.6497e+05 - val_acc: 0.0000e+00\n",
      "Epoch 40/500\n",
      "1s - loss: 114.3144 - r2_keras: 0.2723 - acc: 0.0000e+00 - val_loss: 85.2441 - val_r2_keras: -6.9961e+06 - val_acc: 0.0000e+00\n",
      "Epoch 41/500\n",
      "1s - loss: 126.0883 - r2_keras: 0.2016 - acc: 8.9074e-04 - val_loss: 54.9535 - val_r2_keras: -4.9520e+06 - val_acc: 0.0024\n",
      "Epoch 42/500\n",
      "1s - loss: 106.1524 - r2_keras: 0.3222 - acc: 2.9691e-04 - val_loss: 89.7793 - val_r2_keras: -6.1976e+06 - val_acc: 0.0012\n",
      "Epoch 43/500\n",
      "1s - loss: 110.1455 - r2_keras: 0.3017 - acc: 8.9074e-04 - val_loss: 73.3975 - val_r2_keras: -2.1602e+06 - val_acc: 0.0000e+00\n",
      "Epoch 44/500\n",
      "1s - loss: 115.2315 - r2_keras: 0.2727 - acc: 2.9691e-04 - val_loss: 63.7917 - val_r2_keras: -4.2316e+06 - val_acc: 0.0000e+00\n",
      "Epoch 45/500\n",
      "1s - loss: 99.7104 - r2_keras: 0.3600 - acc: 8.9074e-04 - val_loss: 63.1029 - val_r2_keras: -2.2315e+06 - val_acc: 0.0000e+00\n",
      "Epoch 46/500\n",
      "1s - loss: 109.6035 - r2_keras: 0.2902 - acc: 5.9382e-04 - val_loss: 57.8596 - val_r2_keras: -4.3716e+06 - val_acc: 0.0000e+00\n",
      "Epoch 47/500\n",
      "1s - loss: 100.1256 - r2_keras: 0.3560 - acc: 5.9382e-04 - val_loss: 72.3891 - val_r2_keras: -1.8068e+06 - val_acc: 0.0000e+00\n",
      "Epoch 48/500\n",
      "1s - loss: 110.5736 - r2_keras: 0.2778 - acc: 0.0012 - val_loss: 54.4557 - val_r2_keras: -4.8450e+06 - val_acc: 0.0012\n",
      "Epoch 49/500\n",
      "1s - loss: 111.2866 - r2_keras: 0.2992 - acc: 0.0000e+00 - val_loss: 83.6428 - val_r2_keras: -3.9271e+06 - val_acc: 0.0000e+00\n",
      "Epoch 50/500\n",
      "1s - loss: 114.8781 - r2_keras: 0.2498 - acc: 5.9382e-04 - val_loss: 63.8141 - val_r2_keras: -3.9301e+06 - val_acc: 0.0000e+00\n",
      "Epoch 51/500\n",
      "1s - loss: 97.6133 - r2_keras: 0.3516 - acc: 2.9691e-04 - val_loss: 52.8710 - val_r2_keras: -2.9872e+06 - val_acc: 0.0000e+00\n",
      "Epoch 52/500\n",
      "1s - loss: 95.7305 - r2_keras: 0.3928 - acc: 0.0012 - val_loss: 67.2486 - val_r2_keras: -3.3753e+06 - val_acc: 0.0000e+00\n",
      "Epoch 53/500\n",
      "1s - loss: 89.4506 - r2_keras: 0.4051 - acc: 0.0012 - val_loss: 56.6636 - val_r2_keras: -4.8554e+06 - val_acc: 0.0012\n",
      "Epoch 00052: early stopping\n",
      "Fold 4: Score 0.570636\n",
      "=====================\n",
      "Final Score 0.423734\n",
      "=====================\n"
     ]
    }
   ],
   "source": [
    "#K-FOLD\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits = n_splits)\n",
    "kf.get_n_splits(X_train_all)\n",
    "\n",
    "predictions = np.zeros((X_train_all.shape[0], n_splits))\n",
    "score = 0\n",
    "\n",
    "for fold, (ind_train, ind_valid) in enumerate(kf.split(X_train_all)):\n",
    "\n",
    "    X_train, X_valid = X_train_all[ind_train, :], X_train_all[ind_valid, :]\n",
    "    y_train, y_valid = y_train_all[ind_train], y_train_all[ind_valid]\n",
    "\n",
    "    # fit estimator\n",
    "    history = estimator.fit(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        epochs = 500,\n",
    "        validation_data = (X_valid, y_valid),\n",
    "        verbose = 2,\n",
    "        callbacks = callbacks,\n",
    "        shuffle = True\n",
    "    )\n",
    "    \n",
    "    pred = history.model.predict(X_valid)\n",
    "    \n",
    "    score_fold = r2_score(y_valid, pred)\n",
    "    score += score_fold\n",
    "\n",
    "    print('Fold %d: Score %f'%(fold, score_fold))\n",
    "\n",
    "\n",
    "score /= n_splits\n",
    "\n",
    "print('=====================')\n",
    "\n",
    "print( 'Final Score %f'%score)\n",
    "\n",
    "print('=====================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57063611591743879"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_valid, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAD8CAYAAACW/ATfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsIPreAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f34f4ee49e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(pred, y_valid)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
